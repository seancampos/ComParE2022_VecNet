{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.insert(0, os.path.abspath('../lib'))\n",
    "\n",
    "import config\n",
    "from evaluate import get_results, get_results_multiclass, compute_plot_roc_multiclass\n",
    "\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Mosquito Species Classification (MSC)\n",
    "This code is complementary to the paper: HumBugDB: a large-scale acoustic mosquito dataset. Section B of `/docs/` gives detail on the meaning of the metadata fields that are present in the `csv` file `config.data_df`, while Section C describes in more detail the models used here as baselines.\n",
    "\n",
    "\n",
    "This notebook provides the interface to partition data, extract features, train a BNN model in either PyTorch or Keras and evaluate its accuracy, precision-recall, confusion matrices and uncertainty metrics. Settings are specified in `config.py` and `config_pytorch.py` or `config_keras.py` which are located in `../lib`. Functions are imported from data and feature processing code in `../lib/feat_util.py`, model training in `../lib/runTorchMultiClass.py` or `../lib/runKeras.py` and evaluation in `../lib/evaluate.py`.\n",
    "\n",
    "### Data and feature configuration `config.py`\n",
    "Specify the metadata (csv) location in `data_df`, with the location of the raw wave files in `data_dir`. The desired output for the features is set by `dir_out`. Model objects will be saved to `../models/PyTorch/` for PyTorch, or `../models/keras/` for Keras models.\n",
    "\n",
    "#### Feat A\n",
    "Feat A:  features extracted for [VGGish](https://github.com/harritaylor/torchvggish)'s model class, imported from `feat_vggish.py`. Edits can be made in `lib/PyTorch/vggish/{mel_features.py, vggish_input.py, vggish_params.py}`. A further discussion on feature transformations is given in Section B.3 of the [HumBugDB supplement](https://github.com/HumBug-Mosquito/HumBugDB/blob/devel/docs/NeurIPS_2021_HumBugDB_Supplement.pdf).\n",
    "\n",
    "\n",
    "#### Feat B\n",
    "Feat B uses log-mel features with `librosa`, configurable in `config.py` with the sample rate `rate`, to which data is re-sampled on loading, a window size `win_size` which determines the size of a training window (in number of _feature_ windows), `step_size`, which determines the step size taken by the window, `NFFT`, and `n_hop`, which are parameters for the core STFT transform upon which log-mel feature extraction is based. Finally, `n_feat` determines the number of mel-frequency bands.\n",
    "\n",
    "In `librosa`, we can calculate the value of `win_size` to achieve a user's desired `duration` for a label as follows:\n",
    "\n",
    "`win_size` = `duration` / `frame_duration`, where `frame_duration` = `n_hop`/`rate`. Librosa uses a default `hop_length` of `NFFT/4`.\n",
    "The default values in `config.py` are optimised for `rate` = 8000 with  `win_size` = 30, `NFFT` = 2048, `n_hop` = `default`,  to achieve a label duration of $30 \\times 2048/(4\\times 8000) = 1.92$ (s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose Keras or PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = 'PyTorch'\n",
    "\n",
    "if library == 'PyTorch':\n",
    "    from PyTorch.runTorchMultiClass import (train_model, load_model, evaluate_model, evaluate_model_aggregated,\n",
    "    Resnet50DropoutFull, Resnet18DropoutFull, Resnet, VGGishDropout, VGGishDropoutFeatB)\n",
    "    from PyTorch import config_pytorch\n",
    "elif library == 'Keras':\n",
    "    from tensorflow import keras\n",
    "    from Keras.runKeras import train_model, load_model\n",
    "    from evaluate import evaluate_model, evaluate_model_aggregated\n",
    "else:\n",
    "    print('Library:', library, 'not supported. Please add your own code for support of that framework.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data selection for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select IHI Tanzania cup data to use for multi-species classification\n",
    "\n",
    "df = pd.read_csv(config.data_df)\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>219949</td>\n",
       "      <td>65.097143</td>\n",
       "      <td>IFA_17_24_664_background.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>background</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>221103</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>221111</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>221110</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>221149</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>222615</td>\n",
       "      <td>30.720000</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>222585</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>222586</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>222596</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>222614</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2673 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     length                          name  sample_rate  \\\n",
       "1878  219949  65.097143  IFA_17_24_664_background.wav        44100   \n",
       "1879  221103   2.560000             IFA_17_24_664.wav        44100   \n",
       "1880  221111   2.560000             IFA_17_25_665.wav        44100   \n",
       "1881  221110   2.560000             IFA_17_25_665.wav        44100   \n",
       "1882  221149   2.560000             IFA_17_26_666.wav        44100   \n",
       "...      ...        ...                           ...          ...   \n",
       "4546  222615  30.720000            IFA_86_39_3439.wav        44100   \n",
       "4547  222585  25.600000            IFA_86_40_3440.wav        44100   \n",
       "4548  222586  40.900000            IFA_87_10_3450.wav        44100   \n",
       "4549  222596  40.900000            IFA_87_11_3451.wav        44100   \n",
       "4550  222614  38.400000            IFA_87_12_3452.wav        44100   \n",
       "\n",
       "     record_datetime  sound_type         species  gender  fed plurality  age  \\\n",
       "1878  30-01-20 00:00  background             NaN     NaN  NaN       NaN  NaN   \n",
       "1879  30-01-20 00:00    mosquito    ma africanus  Female    f    Single  NaN   \n",
       "1880  30-01-20 00:00    mosquito    ma africanus  Female    f    Single  NaN   \n",
       "1881  30-01-20 00:00    mosquito    ma africanus  Female    f    Single  NaN   \n",
       "1882  30-01-20 00:00    mosquito   an arabiensis  Female    f    Single  NaN   \n",
       "...              ...         ...             ...     ...  ...       ...  ...   \n",
       "4546  23-08-20 00:00    mosquito  an funestus ss  Female    f    Single  NaN   \n",
       "4547  23-08-20 00:00    mosquito  an funestus ss  Female    f    Single  NaN   \n",
       "4548  23-08-20 00:00    mosquito  an funestus ss  Female    f    Single  NaN   \n",
       "4549  23-08-20 00:00    mosquito  an funestus ss  Female    f    Single  NaN   \n",
       "4550  23-08-20 00:00    mosquito  an funestus ss  Female    f    Single  NaN   \n",
       "\n",
       "     method mic_type device_type   country            district  province  \\\n",
       "1878    HBN  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "1879    HBN  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "1880    HBN  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "1881    HBN  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "1882    HBN  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "...     ...      ...         ...       ...                 ...       ...   \n",
       "4546     LT  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "4547     LT  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "4548     LT  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "4549     LT  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "4550     LT  telinga      tascam  Tanzania  Kilombero District  Morogoro   \n",
       "\n",
       "        place location_type  \n",
       "1878  Ifakara           cup  \n",
       "1879  Ifakara           cup  \n",
       "1880  Ifakara           cup  \n",
       "1881  Ifakara           cup  \n",
       "1882  Ifakara           cup  \n",
       "...       ...           ...  \n",
       "4546  Ifakara           cup  \n",
       "4547  Ifakara           cup  \n",
       "4548  Ifakara           cup  \n",
       "4549  Ifakara           cup  \n",
       "4550  Ifakara           cup  \n",
       "\n",
       "[2673 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select list of classes with sufficient samples for significant analysis. Ordered with similar groups in adjacent classes.\n",
    "\n",
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_type = 'FeatB'\n",
    "\n",
    "if feat_type == 'FeatA': #VGGish features (Feat. A)\n",
    "    from feat_vggish import get_train_test_multispecies, reshape_feat    \n",
    "elif feat_type == 'FeatB': #log-mel-128 win 30 step 5 train, step 30 test, features (Feat. B)\n",
    "    from feat_util import get_train_test_multispecies, reshape_feat\n",
    "else:\n",
    "    print('Features:', feat_type, 'not defined. Please check spelling or add your own code for support of those features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feats, expected runtime ~14 mins train, ~5mins test if pickle does not exist yet.\n",
    "random_seed = 42\n",
    "X_train, y_train, X_test, y_test = get_train_test_multispecies(df_all, classes, random_seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feat_type == 'FeatA':\n",
    "    X_train_CNN, y_train_CNN = reshape_feat(X_train, y_train)\n",
    "elif feat_type == 'FeatB':\n",
    "    X_train_CNN, y_train_CNN = reshape_feat(X_train, y_train, config.win_size, config.step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras training code\n",
    "# class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(y_train_CNN)),y=np.array(y_train_CNN))\n",
    "# #model = train_model(X_train_CNN, y_train_CNN, class_weight = class_weights)\n",
    "# print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(y_train_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n",
      "Applying class weights: [0.31350527 0.57350842 3.63617473 0.61592673 2.28963131 4.4278565\n",
      " 2.75332168 7.03080357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dli/task/Capstone-HumBug/lib/PyTorch/runTorchMultiClass.py:177: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  class_weight = torch.tensor([class_weight]).squeeze().float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e0_2022_09_20_15_16_33.pth\n",
      "Epoch: 0, Train Loss: 2.15925207, Train Acc: 0.13425614, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e1_2022_09_20_15_18_01.pth\n",
      "Epoch: 1, Train Loss: 1.89982231, Train Acc: 0.19014541, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e2_2022_09_20_15_19_29.pth\n",
      "Epoch: 2, Train Loss: 1.77612076, Train Acc: 0.25921646, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e3_2022_09_20_15_20_56.pth\n",
      "Epoch: 3, Train Loss: 1.66561869, Train Acc: 0.30073021, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e4_2022_09_20_15_22_24.pth\n",
      "Epoch: 4, Train Loss: 1.58048431, Train Acc: 0.33221157, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e5_2022_09_20_15_23_51.pth\n",
      "Epoch: 5, Train Loss: 1.49643635, Train Acc: 0.35990857, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e6_2022_09_20_15_25_19.pth\n",
      "Epoch: 6, Train Loss: 1.43042424, Train Acc: 0.36848054, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e7_2022_09_20_15_26_47.pth\n",
      "Epoch: 7, Train Loss: 1.38057247, Train Acc: 0.38366880, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e8_2022_09_20_15_28_15.pth\n",
      "Epoch: 8, Train Loss: 1.31746375, Train Acc: 0.40354308, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e9_2022_09_20_15_29_42.pth\n",
      "Epoch: 9, Train Loss: 1.27598160, Train Acc: 0.41592482, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e10_2022_09_20_15_31_10.pth\n",
      "Epoch: 10, Train Loss: 1.23939201, Train Acc: 0.42598260, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e11_2022_09_20_15_32_37.pth\n",
      "Epoch: 11, Train Loss: 1.20368302, Train Acc: 0.43812306, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e12_2022_09_20_15_34_05.pth\n",
      "Epoch: 12, Train Loss: 1.16907731, Train Acc: 0.44777446, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e13_2022_09_20_15_35_33.pth\n",
      "Epoch: 13, Train Loss: 1.13835254, Train Acc: 0.45679091, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e14_2022_09_20_15_37_00.pth\n",
      "Epoch: 14, Train Loss: 1.11466171, Train Acc: 0.46325481, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e15_2022_09_20_15_38_28.pth\n",
      "Epoch: 15, Train Loss: 1.08753988, Train Acc: 0.47159820, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e16_2022_09_20_15_39_55.pth\n",
      "Epoch: 16, Train Loss: 1.05872751, Train Acc: 0.47641120, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e17_2022_09_20_15_41_23.pth\n",
      "Epoch: 17, Train Loss: 1.04087814, Train Acc: 0.48224014, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e18_2022_09_20_15_42_51.pth\n",
      "Epoch: 18, Train Loss: 1.00851445, Train Acc: 0.49369484, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e19_2022_09_20_15_44_18.pth\n",
      "Epoch: 19, Train Loss: 1.00097600, Train Acc: 0.49620928, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e20_2022_09_20_15_45_46.pth\n",
      "Epoch: 20, Train Loss: 0.97450256, Train Acc: 0.50290177, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e21_2022_09_20_15_47_14.pth\n",
      "Epoch: 21, Train Loss: 0.95671430, Train Acc: 0.50934028, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e22_2022_09_20_15_48_41.pth\n",
      "Epoch: 22, Train Loss: 0.93696755, Train Acc: 0.51417868, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e23_2022_09_20_15_50_09.pth\n",
      "Epoch: 23, Train Loss: 0.91377642, Train Acc: 0.52338561, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e24_2022_09_20_15_51_37.pth\n",
      "Epoch: 24, Train Loss: 0.90248591, Train Acc: 0.52548098, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e25_2022_09_20_15_53_05.pth\n",
      "Epoch: 25, Train Loss: 0.89328884, Train Acc: 0.52672551, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e26_2022_09_20_15_54_32.pth\n",
      "Epoch: 26, Train Loss: 0.88180538, Train Acc: 0.52970982, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e27_2022_09_20_15_56_00.pth\n",
      "Epoch: 27, Train Loss: 0.85933568, Train Acc: 0.53911994, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e28_2022_09_20_15_57_27.pth\n",
      "Epoch: 28, Train Loss: 0.84942685, Train Acc: 0.54380596, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e29_2022_09_20_15_58_55.pth\n",
      "Epoch: 29, Train Loss: 0.83834075, Train Acc: 0.54647279, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e30_2022_09_20_16_00_22.pth\n",
      "Epoch: 30, Train Loss: 0.82922306, Train Acc: 0.55090482, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e31_2022_09_20_16_01_50.pth\n",
      "Epoch: 31, Train Loss: 0.81275447, Train Acc: 0.55636548, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e32_2022_09_20_16_03_17.pth\n",
      "Epoch: 32, Train Loss: 0.80455112, Train Acc: 0.55747032, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e33_2022_09_20_16_04_44.pth\n",
      "Epoch: 33, Train Loss: 0.79312195, Train Acc: 0.56006096, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e34_2022_09_20_16_06_12.pth\n",
      "Epoch: 34, Train Loss: 0.77783048, Train Acc: 0.57011874, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e35_2022_09_20_16_07_39.pth\n",
      "Epoch: 35, Train Loss: 0.77673336, Train Acc: 0.57118547, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e36_2022_09_20_16_09_06.pth\n",
      "Epoch: 36, Train Loss: 0.76392957, Train Acc: 0.57253159, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e37_2022_09_20_16_10_34.pth\n",
      "Epoch: 37, Train Loss: 0.74751127, Train Acc: 0.57982094, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e38_2022_09_20_16_12_01.pth\n",
      "Epoch: 38, Train Loss: 0.74606687, Train Acc: 0.58006223, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e39_2022_09_20_16_13_29.pth\n",
      "Epoch: 39, Train Loss: 0.72903772, Train Acc: 0.58509112, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e40_2022_09_20_16_14_57.pth\n",
      "Epoch: 40, Train Loss: 0.72242090, Train Acc: 0.58632294, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 41, Train Loss: 0.73174526, Train Acc: 0.58603086, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e42_2022_09_20_16_17_51.pth\n",
      "Epoch: 42, Train Loss: 0.70835449, Train Acc: 0.59288844, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e43_2022_09_20_16_19_19.pth\n",
      "Epoch: 43, Train Loss: 0.70363945, Train Acc: 0.59516160, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e44_2022_09_20_16_20_47.pth\n",
      "Epoch: 44, Train Loss: 0.69502291, Train Acc: 0.59904756, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e45_2022_09_20_16_22_14.pth\n",
      "Epoch: 45, Train Loss: 0.68622402, Train Acc: 0.60469871, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e46_2022_09_20_16_23_42.pth\n",
      "Epoch: 46, Train Loss: 0.68549685, Train Acc: 0.60618452, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 47, Train Loss: 0.67865823, Train Acc: 0.60543527, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e48_2022_09_20_16_26_37.pth\n",
      "Epoch: 48, Train Loss: 0.66672995, Train Acc: 0.61022287, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 49, Train Loss: 0.67348600, Train Acc: 0.60966411, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e50_2022_09_20_16_29_32.pth\n",
      "Epoch: 50, Train Loss: 0.66274008, Train Acc: 0.61273732, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e51_2022_09_20_16_30_59.pth\n",
      "Epoch: 51, Train Loss: 0.65532308, Train Acc: 0.61410883, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e52_2022_09_20_16_32_27.pth\n",
      "Epoch: 52, Train Loss: 0.65066612, Train Acc: 0.61802019, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e53_2022_09_20_16_33_54.pth\n",
      "Epoch: 53, Train Loss: 0.63818519, Train Acc: 0.62029335, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e54_2022_09_20_16_35_22.pth\n",
      "Epoch: 54, Train Loss: 0.63978872, Train Acc: 0.62213474, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e55_2022_09_20_16_36_50.pth\n",
      "Epoch: 55, Train Loss: 0.63740061, Train Acc: 0.62655407, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e56_2022_09_20_16_38_18.pth\n",
      "Epoch: 56, Train Loss: 0.63213071, Train Acc: 0.62734142, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e57_2022_09_20_16_39_45.pth\n",
      "Epoch: 57, Train Loss: 0.62125256, Train Acc: 0.62791288, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e58_2022_09_20_16_41_13.pth\n",
      "Epoch: 58, Train Loss: 0.61316660, Train Acc: 0.63370373, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e59_2022_09_20_16_42_41.pth\n",
      "Epoch: 59, Train Loss: 0.61370430, Train Acc: 0.63391961, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e60_2022_09_20_16_44_09.pth\n",
      "Epoch: 60, Train Loss: 0.60533361, Train Acc: 0.63902470, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 61, Train Loss: 0.60281545, Train Acc: 0.63901200, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e62_2022_09_20_16_47_03.pth\n",
      "Epoch: 62, Train Loss: 0.60218121, Train Acc: 0.64099308, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e63_2022_09_20_16_48_30.pth\n",
      "Epoch: 63, Train Loss: 0.59607903, Train Acc: 0.64651724, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e64_2022_09_20_16_49_58.pth\n",
      "Epoch: 64, Train Loss: 0.58644343, Train Acc: 0.64654264, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 65, Train Loss: 0.59176244, Train Acc: 0.64559020, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e66_2022_09_20_16_52_52.pth\n",
      "Epoch: 66, Train Loss: 0.58123447, Train Acc: 0.65107626, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 67, Train Loss: 0.58392046, Train Acc: 0.64686012, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 68, Train Loss: 0.58033887, Train Acc: 0.65063179, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e69_2022_09_20_16_57_14.pth\n",
      "Epoch: 69, Train Loss: 0.57550706, Train Acc: 0.65427646, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e70_2022_09_20_16_58_42.pth\n",
      "Epoch: 70, Train Loss: 0.56708002, Train Acc: 0.65656232, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 71, Train Loss: 0.57030220, Train Acc: 0.65507651, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e72_2022_09_20_17_01_36.pth\n",
      "Epoch: 72, Train Loss: 0.56123383, Train Acc: 0.65936885, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 73, Train Loss: 0.56040391, Train Acc: 0.65936885, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e74_2022_09_20_17_04_30.pth\n",
      "Epoch: 74, Train Loss: 0.56076122, Train Acc: 0.66204838, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e75_2022_09_20_17_05_58.pth\n",
      "Epoch: 75, Train Loss: 0.55180970, Train Acc: 0.66535018, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 76, Train Loss: 0.54903513, Train Acc: 0.66472792, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e77_2022_09_20_17_08_52.pth\n",
      "Epoch: 77, Train Loss: 0.54339100, Train Acc: 0.66894406, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e78_2022_09_20_17_10_20.pth\n",
      "Epoch: 78, Train Loss: 0.53892979, Train Acc: 0.67015049, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 79, Train Loss: 0.54523115, Train Acc: 0.66730586, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e80_2022_09_20_17_13_13.pth\n",
      "Epoch: 80, Train Loss: 0.53642711, Train Acc: 0.67370627, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 81, Train Loss: 0.54226233, Train Acc: 0.67040447, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 82, Train Loss: 0.52362051, Train Acc: 0.67307131, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e83_2022_09_20_17_17_35.pth\n",
      "Epoch: 83, Train Loss: 0.53021224, Train Acc: 0.67601752, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 84, Train Loss: 0.52716988, Train Acc: 0.67441742, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e85_2022_09_20_17_20_29.pth\n",
      "Epoch: 85, Train Loss: 0.52432246, Train Acc: 0.67939552, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 86, Train Loss: 0.52564873, Train Acc: 0.67439202, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e87_2022_09_20_17_23_24.pth\n",
      "Epoch: 87, Train Loss: 0.52064951, Train Acc: 0.68116071, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 88, Train Loss: 0.52168467, Train Acc: 0.67948441, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e89_2022_09_20_17_26_18.pth\n",
      "Epoch: 89, Train Loss: 0.51605844, Train Acc: 0.68493238, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e90_2022_09_20_17_27_46.pth\n",
      "Epoch: 90, Train Loss: 0.50602742, Train Acc: 0.68681186, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e91_2022_09_20_17_29_13.pth\n",
      "Epoch: 91, Train Loss: 0.50895754, Train Acc: 0.68867865, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 92, Train Loss: 0.50325282, Train Acc: 0.68796749, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 93, Train Loss: 0.50583999, Train Acc: 0.68700235, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 94, Train Loss: 0.51014320, Train Acc: 0.68858975, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e95_2022_09_20_17_35_01.pth\n",
      "Epoch: 95, Train Loss: 0.50273171, Train Acc: 0.68988507, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e96_2022_09_20_17_36_29.pth\n",
      "Epoch: 96, Train Loss: 0.49620640, Train Acc: 0.69050733, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e97_2022_09_20_17_37_57.pth\n",
      "Epoch: 97, Train Loss: 0.50178566, Train Acc: 0.69205664, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 98, Train Loss: 0.50652147, Train Acc: 0.69097720, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e99_2022_09_20_17_40_51.pth\n",
      "Epoch: 99, Train Loss: 0.49893820, Train Acc: 0.69330116, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 100, Train Loss: 0.49960415, Train Acc: 0.69223443, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e101_2022_09_20_17_43_45.pth\n",
      "Epoch: 101, Train Loss: 0.48495573, Train Acc: 0.69637437, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e102_2022_09_20_17_45_13.pth\n",
      "Epoch: 102, Train Loss: 0.48182159, Train Acc: 0.70028573, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 103, Train Loss: 0.48717277, Train Acc: 0.69871103, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 104, Train Loss: 0.49239969, Train Acc: 0.69833005, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e105_2022_09_20_17_49_34.pth\n",
      "Epoch: 105, Train Loss: 0.48468758, Train Acc: 0.70083180, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 106, Train Loss: 0.48427409, Train Acc: 0.70000635, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e107_2022_09_20_17_52_28.pth\n",
      "Epoch: 107, Train Loss: 0.48421789, Train Acc: 0.70126357, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 108, Train Loss: 0.48541589, Train Acc: 0.69893962, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e109_2022_09_20_17_55_22.pth\n",
      "Epoch: 109, Train Loss: 0.48081765, Train Acc: 0.70433678, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e110_2022_09_20_17_56_50.pth\n",
      "Epoch: 110, Train Loss: 0.47715952, Train Acc: 0.70847673, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 111, Train Loss: 0.46764773, Train Acc: 0.70695282, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 112, Train Loss: 0.47221564, Train Acc: 0.70815925, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 113, Train Loss: 0.47127562, Train Acc: 0.70671154, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 114, Train Loss: 0.46741655, Train Acc: 0.70824814, overrun_counter 4\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 115, Train Loss: 0.46820469, Train Acc: 0.70743539, overrun_counter 5\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e116_2022_09_20_18_05_33.pth\n",
      "Epoch: 116, Train Loss: 0.45630453, Train Acc: 0.71137215, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e117_2022_09_20_18_07_01.pth\n",
      "Epoch: 117, Train Loss: 0.46559138, Train Acc: 0.71176583, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 118, Train Loss: 0.47020560, Train Acc: 0.70941647, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 119, Train Loss: 0.46390092, Train Acc: 0.71143565, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e120_2022_09_20_18_11_21.pth\n",
      "Epoch: 120, Train Loss: 0.46234120, Train Acc: 0.71191822, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e121_2022_09_20_18_12_49.pth\n",
      "Epoch: 121, Train Loss: 0.45812610, Train Acc: 0.71309924, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e122_2022_09_20_18_14_17.pth\n",
      "Epoch: 122, Train Loss: 0.45527803, Train Acc: 0.71732808, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 123, Train Loss: 0.46096160, Train Acc: 0.71354372, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 124, Train Loss: 0.46273819, Train Acc: 0.71613436, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 125, Train Loss: 0.45714083, Train Acc: 0.71586767, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e126_2022_09_20_18_20_05.pth\n",
      "Epoch: 126, Train Loss: 0.44746972, Train Acc: 0.71767096, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 127, Train Loss: 0.45719228, Train Acc: 0.71730269, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e128_2022_09_20_18_23_00.pth\n",
      "Epoch: 128, Train Loss: 0.45019790, Train Acc: 0.71957585, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e129_2022_09_20_18_24_28.pth\n",
      "Epoch: 129, Train Loss: 0.44523269, Train Acc: 0.72094736, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 130, Train Loss: 0.44114352, Train Acc: 0.72029970, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e131_2022_09_20_18_27_22.pth\n",
      "Epoch: 131, Train Loss: 0.43891896, Train Acc: 0.72322052, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e132_2022_09_20_18_28_50.pth\n",
      "Epoch: 132, Train Loss: 0.44165804, Train Acc: 0.72363960, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 133, Train Loss: 0.44680463, Train Acc: 0.72183631, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 134, Train Loss: 0.44390764, Train Acc: 0.72154423, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e135_2022_09_20_18_33_11.pth\n",
      "Epoch: 135, Train Loss: 0.45126926, Train Acc: 0.72379199, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e136_2022_09_20_18_34_38.pth\n",
      "Epoch: 136, Train Loss: 0.43781871, Train Acc: 0.72676360, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 137, Train Loss: 0.44537049, Train Acc: 0.72521430, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e138_2022_09_20_18_37_33.pth\n",
      "Epoch: 138, Train Loss: 0.43171230, Train Acc: 0.72744936, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e139_2022_09_20_18_39_00.pth\n",
      "Epoch: 139, Train Loss: 0.43050133, Train Acc: 0.72817322, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 140, Train Loss: 0.43799842, Train Acc: 0.72681440, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 141, Train Loss: 0.43658551, Train Acc: 0.72710648, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 142, Train Loss: 0.43368226, Train Acc: 0.72737317, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e143_2022_09_20_18_44_47.pth\n",
      "Epoch: 143, Train Loss: 0.43003718, Train Acc: 0.73197028, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 144, Train Loss: 0.43511888, Train Acc: 0.73078926, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e145_2022_09_20_18_47_40.pth\n",
      "Epoch: 145, Train Loss: 0.42432564, Train Acc: 0.73285923, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 146, Train Loss: 0.43195555, Train Acc: 0.73177980, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e147_2022_09_20_18_50_34.pth\n",
      "Epoch: 147, Train Loss: 0.42459283, Train Acc: 0.73383707, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 148, Train Loss: 0.42828389, Train Acc: 0.73344339, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e149_2022_09_20_18_53_29.pth\n",
      "Epoch: 149, Train Loss: 0.41891665, Train Acc: 0.73644041, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 150, Train Loss: 0.42623476, Train Acc: 0.73532288, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e151_2022_09_20_18_56_23.pth\n",
      "Epoch: 151, Train Loss: 0.42139180, Train Acc: 0.73689758, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 152, Train Loss: 0.42195892, Train Acc: 0.73564036, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 153, Train Loss: 0.42038548, Train Acc: 0.73501810, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 154, Train Loss: 0.42323402, Train Acc: 0.73511969, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e155_2022_09_20_19_02_13.pth\n",
      "Epoch: 155, Train Loss: 0.41777998, Train Acc: 0.73861198, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e156_2022_09_20_19_03_41.pth\n",
      "Epoch: 156, Train Loss: 0.41396568, Train Acc: 0.73938663, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e157_2022_09_20_19_05_08.pth\n",
      "Epoch: 157, Train Loss: 0.41497778, Train Acc: 0.74139310, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 158, Train Loss: 0.41475254, Train Acc: 0.73906915, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 159, Train Loss: 0.40707603, Train Acc: 0.74078354, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 160, Train Loss: 0.41720488, Train Acc: 0.73998349, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e161_2022_09_20_19_10_56.pth\n",
      "Epoch: 161, Train Loss: 0.41316285, Train Acc: 0.74266303, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 162, Train Loss: 0.42115463, Train Acc: 0.73865007, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e163_2022_09_20_19_13_51.pth\n",
      "Epoch: 163, Train Loss: 0.40889347, Train Acc: 0.74338688, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e164_2022_09_20_19_15_19.pth\n",
      "Epoch: 164, Train Loss: 0.41201042, Train Acc: 0.74376786, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 165, Train Loss: 0.41836749, Train Acc: 0.74089783, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e166_2022_09_20_19_18_13.pth\n",
      "Epoch: 166, Train Loss: 0.39613240, Train Acc: 0.74701886, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 167, Train Loss: 0.40879806, Train Acc: 0.74245984, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 168, Train Loss: 0.41277771, Train Acc: 0.74162169, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 169, Train Loss: 0.40917324, Train Acc: 0.74185028, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 170, Train Loss: 0.40664238, Train Acc: 0.74488539, overrun_counter 4\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 171, Train Loss: 0.41349790, Train Acc: 0.74525367, overrun_counter 5\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e172_2022_09_20_19_26_56.pth\n",
      "Epoch: 172, Train Loss: 0.39434090, Train Acc: 0.75171757, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 173, Train Loss: 0.40471574, Train Acc: 0.74798400, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 174, Train Loss: 0.39744457, Train Acc: 0.75145089, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 175, Train Loss: 0.39904102, Train Acc: 0.74996508, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 176, Train Loss: 0.40869879, Train Acc: 0.74769192, overrun_counter 4\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 177, Train Loss: 0.39696792, Train Acc: 0.75085402, overrun_counter 5\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 178, Train Loss: 0.40563860, Train Acc: 0.74949521, overrun_counter 6\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 179, Train Loss: 0.39494184, Train Acc: 0.75086672, overrun_counter 7\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 180, Train Loss: 0.40028209, Train Acc: 0.75042225, overrun_counter 8\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 181, Train Loss: 0.40104765, Train Acc: 0.74680297, overrun_counter 9\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e182_2022_09_20_19_41_27.pth\n",
      "Epoch: 182, Train Loss: 0.39061258, Train Acc: 0.75316528, overrun_counter 0\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 183, Train Loss: 0.39775346, Train Acc: 0.75267001, overrun_counter 1\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 184, Train Loss: 0.39652645, Train Acc: 0.75035875, overrun_counter 2\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 185, Train Loss: 0.39296041, Train Acc: 0.75236523, overrun_counter 3\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 186, Train Loss: 0.39959866, Train Acc: 0.75166677, overrun_counter 4\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Epoch: 187, Train Loss: 0.39487306, Train Acc: 0.75310178, overrun_counter 5\n",
      "all_y all_y_pred (78745, 1) (78745,)\n",
      "Saving model to: ../outputs/models/pytorch/model_e188_2022_09_20_19_50_10.pth\n",
      "Epoch: 188, Train Loss: 0.39043490, Train Acc: 0.75481618, overrun_counter 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f0e4447c3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Choose from {ResnetDropoutFull, Resnet, VGGishDropout} as defined in runTorchMulticlass.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclass_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResnet50DropoutFull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dli/task/Capstone-HumBug/lib/PyTorch/runTorchMultiClass.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(x_train, y_train, class_weight, x_val, y_val, model)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;31m# loss = criterion(m(y_pred), y.squeeze())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PyTorch training code, only difference is specification of model object.\n",
    "# Choose from {ResnetDropoutFull, Resnet, VGGishDropout} as defined in runTorchMulticlass.py\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(y_train_CNN)),y=np.array(y_train_CNN))\n",
    "model = train_model(X_train_CNN, y_train_CNN, class_weight = class_weights, model = Resnet50DropoutFull(n_classes = 8, dropout=0.2))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from checkpoint (optional)\n",
    "\n",
    "The full list of trained model names, and classes, and their hyperparameters used is given in the [species classification documentation](https://github.com/HumBug-Mosquito/HumBugDB/blob/master/docs/mosquito_species_classification.md).\n",
    "\n",
    "The binaries for the trained models are supplied in the latest [GitHub release](https://github.com/HumBug-Mosquito/HumBugDB/releases/tag/2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to load PyTorch model. Select from {Resnet18DropoutFull, Resnet, VGGishDropoutFeatB, ...} as defined in runTorchMultiClass.py\n",
    "filepath = '../outputs/models/pytorch/'\n",
    "\n",
    "filepath = '../outputs/models/pytorch/model_e19_2022_09_20_01_50_52.pth'\n",
    "model_name = 'Resnet50DropoutFull'\n",
    "\n",
    "# warning: poor performance for featB seed 5, resnet50dropoutfull: model_e73_2021_08_01_18_19_10.pth\n",
    "# model = load_model(filepath + model_name, model=Resnet50DropoutFull(n_classes=8, dropout=0.2))\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Example code to load Keras model\n",
    "\n",
    "filepath = '../outputs/models/keras/'\n",
    "filepath = '../outputs/models/reproducibility/MSC_trained_models/'\n",
    "model_name = 'Win_30_Stride_5_2021_07_26_12_59_05-e80accuracy0.9635.hdf5'\n",
    "\n",
    "model = load_model(filepath + model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if feat_type == 'FeatA':\n",
    "    p,y,yt = evaluate_model_aggregated(model, X_test, y_test, 30)  # Aggregate windows from feature list (0.96->1.92 s)\n",
    "    get_results_multiclass(yt, p, feat_type + '_seed_' + str(random_seed) +\n",
    "                                     '_'+ model_name, classes)\n",
    "elif feat_type == 'FeatB':\n",
    "    X_test_CNN, y_test_CNN = reshape_feat(X_test, y_test, config.win_size, config.win_size)\n",
    "    preds_list = evaluate_model(model, X_test_CNN, y_test_CNN, 100)  # Predict directly over feature windows (1.92 s)\n",
    "    get_results_multiclass(y_test_CNN, np.mean(preds_list,axis=0), feat_type + '_seed_' + str(random_seed) +\n",
    "                                     '_'+ model_name, classes)\n",
    "else:\n",
    "    'Feature type not supported.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2, sharex=True, sharey=True, figsize=(8,10))\n",
    "\n",
    "for ax, i in zip(axs.ravel(), range(8)):\n",
    "    idx_start = np.where(y_test_CNN==i)[0][0]\n",
    "    if i < 7:\n",
    "        idx_end = np.where(y_test_CNN==i+1)[0][0]\n",
    "    else:\n",
    "        idx_end = len(y_test_CNN)\n",
    "    ax.fill_between([idx_start, idx_end], [1], alpha=0.30, label=r'$y_{\\mathrm{true},' + str(i) + '}$')\n",
    "    ax.plot(np.mean(preds_list,axis=0)[:,i], '.', lw=0.5, ms=1.4, label=r'$y_{\\mathrm{pred},' + str(i) + '}$', rasterized=True)\n",
    "    ax.legend()\n",
    "#     plt.ylim([0, 1.05])\n",
    "#     plt.title(classes[i])\n",
    "#     plt.show()\n",
    "#     plt.show()\n",
    "\n",
    "axs[3,0].set_xlabel('Prediction window')\n",
    "axs[3,1].set_xlabel('Prediction window')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/plots/reproducibility/supplement/' + 'seed_' + str(random_seed) +\n",
    "           '_' + feat_type + model_name + 'softmax.pdf', dpi=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(np.where(y_test_CNN==7)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.mean(preds_list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = []\n",
    "y_pred = []\n",
    "\n",
    "# select random subset\n",
    "for i in range(8):\n",
    "    y_class.append(y_test_CNN[np.where(y_test_CNN==i)][:n_samples])\n",
    "    y_pred.append(y_preds[np.where(y_test_CNN==i)][:n_samples])\n",
    "\n",
    "y_true_resampled = np.hstack(y_class)\n",
    "y_pred_resampled = np.vstack(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_multiclass(y_true_resampled, y_pred_resampled, feat_type + '_seed_' + str(random_seed) +\n",
    "                                 '_'+ model_name + 'UNDERSAMPLED', classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
