{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdedb0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 15 06:22:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   44C    P0    27W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a8e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: timm==0.4.5 in /opt/conda/lib/python3.8/site-packages (0.4.5)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm==0.4.5) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm==0.4.5) (0.11.0a0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm==0.4.5) (4.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm==0.4.5) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm==0.4.5) (9.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (2022.2.9)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (1.21.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (1.2.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (2.16.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (1.6.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (3.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm==0.4.5\n",
    "import IPython.display as ipd\n",
    "!pip install scikit-image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02e4040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d56770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../lib'))\n",
    "import config\n",
    "import config_DK_AST\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from torchvision import datasets\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import skimage.util\n",
    "import pickle\n",
    "import math\n",
    "import collections\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter , filtfilt\n",
    "import scipy.io as sio\n",
    "import scipy.io.wavfile\n",
    "import copy\n",
    "from PyTorch import config_pytorch\n",
    "from PyTorch.runTorch_AST_DK import ASTModel\n",
    "from evaluate import get_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfc5e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the training data = 0\n",
      "The SD of the training data = 0\n"
     ]
    }
   ],
   "source": [
    "# Defining global variables to standardize.\n",
    "\n",
    "train_data_mean = 0\n",
    "train_data_sd = 0\n",
    "# set this to True if you want to call the bandpass filter\n",
    "call_filter = True\n",
    "\n",
    "print(\"The mean of the training data = \" + str(train_data_mean))\n",
    "print(\"The SD of the training data = \" + str(train_data_sd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f9baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb 15 06:23:03 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   43C    P0    27W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da2a9a",
   "metadata": {},
   "source": [
    "## Data Related Functions - Reshaping and Feature Extraction from .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "535e7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feat(data_df, data_dir, rate, min_duration, n_feat , filter_signal = call_filter):\n",
    "    ''' Returns features extracted with Librosa. A list of features, with the number of items equal to the number of input recordings'''\n",
    "    #dk added\n",
    "    #print(\"inside get_feat\")\n",
    "    X = []\n",
    "    y = []\n",
    "    bugs = []\n",
    "    idx = 0\n",
    "    skipped_files = []\n",
    "    \n",
    "    print(\"data_dir = \" + str(data_dir))\n",
    "    print(\"rate = \" + str(rate))\n",
    "    print(\"min_duration = \" + str(min_duration))\n",
    "    print(\"n_feat = \" + str(n_feat))\n",
    "    \n",
    "    \n",
    "    for row_idx_series in data_df.iterrows():\n",
    "        #print(\"row_idx_series...\" + str(row_idx_series))\n",
    "        idx+=1\n",
    "        #print(\"idx = \" + str(idx))\n",
    "        if idx % 100 == 0:\n",
    "            print('Completed', idx, 'of', len(data_df))\n",
    "        row = row_idx_series[1]\n",
    "        #print(\"row->\" + str(row))\n",
    "        label_duration = row['length']\n",
    "        #print(\"label_duration = \" +str(label_duration))\n",
    "        if label_duration > min_duration:\n",
    "            #print(\"if label_duration > min_duration...\")\n",
    "            _, file_format = os.path.splitext(row['name'])\n",
    "            filename = os.path.join(data_dir, str(row['id']) + file_format)\n",
    "            #print(\"filename = \" + str(filename))\n",
    "            length = librosa.get_duration(filename = filename)\n",
    "            #print(\"length from librosa = \" + str(length) )\n",
    "#             assert math.isclose(length,label_duration, rel_tol=0.01), \"File: %s label duration (%.4f) does not match audio length (%.4f)\" % (row['path'], label_duration, length)\n",
    "            \n",
    "            if math.isclose(length,label_duration, rel_tol=0.01):\n",
    "                #print(\"if math.isclose(length,label_duration....\")\n",
    "                signal_file, rate = librosa.load(filename, sr=rate)\n",
    "                #print(\"BEFORE Calling filter....\")\n",
    "                #print(\"Sorted raw signal is -> \" + str(np.sort(signal_file)[::-1] ))\n",
    "                \n",
    "                if filter_signal == True :\n",
    "                    filtered_sig = create_filter(file = filename)\n",
    "                else:\n",
    "                    filtered_sig = signal_file\n",
    "                #print(\"Sorted Filtered SIgnal is ----\" + str(np.sort(filtered_sig)[::-1] ))\n",
    "                \n",
    "                feat = librosa.feature.melspectrogram(filtered_sig, sr=rate, n_mels=n_feat) \n",
    "                #print(\"After librosa.feature.melspectrogram . Shape of feat ->\" + str(feat.shape))\n",
    "                feat = librosa.power_to_db(feat, ref=np.max)\n",
    "                #print(\"After librosa.power_to_db . Shape of feat ->\" + str(feat.shape))\n",
    "                  \n",
    "                #librosa.display.specshow(feat)\n",
    "                if config_DK_AST.norm_per_sample:\n",
    "                    #print(\"Attempting to standardize..\")\n",
    "                    #print(\"mean of the filtered signal - \" + str(np.mean(feat)))\n",
    "                    #print(\"SD of the filtered signal - \" + str(np.std(feat)))\n",
    "                    #feat = (feat-np.mean(feat))/np.std(feat)                \n",
    "                    #print(\"shape of feat...\")\n",
    "                    print(\"..\")\n",
    "                    #print(feat.shape)\n",
    "                X.append(feat)\n",
    "                if row['sound_type'] == 'mosquito':\n",
    "                    y.append(1)\n",
    "                elif row['sound_type']:  # Condition to check we are not adding empty (or unexpected) labels as 0\n",
    "                    y.append(0)\n",
    "            else:\n",
    "                print(\"File: %s label duration (%.4f) does not match audio length (%.4f)\" % (row['name'], label_duration, length))\n",
    "                bugs.append([row['name'], label_duration, length])\n",
    "                \n",
    "        else:\n",
    "            #print(\"inside skipped files\")\n",
    "            skipped_files.append([row['id'], row['name'], label_duration])\n",
    "           # print(\"skipped file = \" + str(skipped_files))\n",
    "            \n",
    "    #print(\"length X = \" + str(len(X)))\n",
    "    #print(\"length y = \" + str(len(y)))\n",
    "    #print(\"before returning from get_feat skipped file = \" + str(skipped_files)  )\n",
    "    return X, y, skipped_files, bugs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba467a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_feat(feats, labels, win_size, step_size):\n",
    "    '''Reshaping features from get_feat to be compatible for classifiers expecting a 2D slice as input. Parameter `win_size` is \n",
    "    given in number of feature windows (in librosa this is the hop length divided by the sample rate.)\n",
    "    Can code to be a function of time and hop length instead in future.'''\n",
    "    from statistics import mean\n",
    "    #print(\"inside reshape_feat....\")\n",
    "    #print(\"Length Input  = \" + str(len(feats)))\n",
    "    feats_windowed_array = []\n",
    "    labels_windowed_array = []\n",
    "    for idx, feat in enumerate(feats):\n",
    "        #print(\"shape of feat = \" + str(np.shape(feat)))\n",
    "        if np.shape(feat)[1] < win_size:\n",
    "            print('Length of recording shorter than supplied window size.') \n",
    "            pass\n",
    "        else:\n",
    "            #create a window\n",
    "            feats_windowed = skimage.util.view_as_windows(feat.T, (win_size,np.shape(feat)[0]), step=step_size)\n",
    "            labels_windowed = np.full(len(feats_windowed), labels[idx])\n",
    "            feats_windowed_array.append(feats_windowed)\n",
    "            labels_windowed_array.append(labels_windowed)\n",
    "          \n",
    "    #numpy.vstack() function is used to stack the sequence of input arrays vertically to make a single array.\n",
    "    #print(\"Length of Feat windowed arraay = \" + str(len(feats_windowed_array)))\n",
    "    #print(\"Mean of features = \" + str(mean(feats_windowed_array)))\n",
    "    #print(\"Std Deviation of features = \")\n",
    "    return np.vstack(feats_windowed_array), np.hstack(labels_windowed_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6361e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_from_df(df_train, df_test_A, df_test_B, debug=False):\n",
    "    #dk added\n",
    "    #print(\"Inside get_train_test_from_df \")\n",
    "    #print(\"Creating Pickle file.. \")\n",
    "    \n",
    "    \n",
    "    pickle_name_train = 'log_mel_feat_train_AST'+str(config.n_feat)+'_win_'+str(config.win_size)+'_step_'+str(config.step_size)+'_norm_'+str(config.norm_per_sample)+'.pickle'\n",
    "    print(\"pickle_name_train = \" + str(pickle_name_train))\n",
    "    # step = window for test (no augmentation of test):\n",
    "    pickle_name_test = 'log_mel_feat_test_AST'+str(config.n_feat)+'_win_'+str(config.win_size)+'_step_'+str(config.win_size)+'_norm_'+str(config.norm_per_sample)+'.pickle'\n",
    "    print(\"pickle_name_test = \" + str(pickle_name_test))\n",
    "    if not os.path.isfile(os.path.join(config.dir_out_MED, pickle_name_train)):\n",
    "        #dk added\n",
    "        print(\"Inside if...when pickle file is not found\")\n",
    "        print('Extracting training features...')\n",
    "        X_train, y_train, skipped_files_train, bugs_train = get_feat(data_df=df_train, data_dir = config_DK_AST.data_dir,\n",
    "                                                                     rate=config_DK_AST.rate, min_duration=config_DK_AST.min_duration,\n",
    "                                                                     n_feat=config.n_feat,filter_signal = call_filter)\n",
    "        #print(\"After returning from get_feat..\")\n",
    "        #print(\"skipped files = \" + str(skipped_files_train))\n",
    "        #print(\"X_Train = \" + str(X_train))\n",
    "        print(\"X_Train len  = \" +str(len(X_train)))\n",
    "        \n",
    "        print(\"before calling reshape....\")\n",
    "        X_train, y_train = reshape_feat(X_train, y_train, config_DK_AST.win_size, config_DK_AST.step_size)\n",
    "        #print(\"After X_train re shape = \" + str(X_train.shape))\n",
    "        \n",
    "        #print(\"THIS IS WHERE STANDARDIZATION CAN GO IN....\")\n",
    "\n",
    "        log_mel_feat_train = {'X_train':X_train, 'y_train':y_train, 'bugs_train':bugs_train}\n",
    "        \n",
    "\n",
    "        if debug:\n",
    "            print('Bugs train', bugs_train)\n",
    "        \n",
    "        with open(os.path.join(config.dir_out_MED, pickle_name_train), 'wb') as f:\n",
    "            pickle.dump(log_mel_feat_train, f, protocol=4)\n",
    "            print('Saved features to:', os.path.join(config.dir_out_MED, pickle_name_train))\n",
    "\n",
    "    else:\n",
    "        print('Loading training features found at:', os.path.join(config.dir_out_MED, pickle_name_train))\n",
    "        with open(os.path.join(config.dir_out_MED, pickle_name_train), 'rb') as input_file:\n",
    "            log_mel_feat = pickle.load(input_file)\n",
    "            X_train = log_mel_feat['X_train']\n",
    "            #print(\"X_train shape = \" + str(X_train.shape))\n",
    "          \n",
    "            y_train = log_mel_feat['y_train']\n",
    "\n",
    "    if not os.path.isfile(os.path.join(config.dir_out_MED, pickle_name_test)):\n",
    "        print('Extracting test features...')\n",
    "\n",
    "        X_test_A, y_test_A, skipped_files_test_A, bugs_test_A = get_feat(data_df= df_test_A, data_dir = config_DK_AST.data_dir,\n",
    "                                                                         rate=config_DK_AST.rate, min_duration=config_DK_AST.min_duration,\n",
    "                                                                         n_feat=config_DK_AST.n_feat,filter_signal = call_filter)\n",
    "        \n",
    "        X_test_B, y_test_B, skipped_files_test_B, bugs_test_B = get_feat(data_df= df_test_B, data_dir = config_DK_AST.data_dir,\n",
    "                                                                         rate=config_DK_AST.rate, min_duration=config_DK_AST.min_duration,\n",
    "                                                                         n_feat=config_DK_AST.n_feat,filter_signal = call_filter)\n",
    "        X_test_A, y_test_A = reshape_feat(X_test_A, y_test_A, config_DK_AST.win_size, config_DK_AST.win_size)  # Test should be strided with step = window.\n",
    "        X_test_B, y_test_B = reshape_feat(X_test_B, y_test_B, config_DK_AST.win_size, config_DK_AST.win_size)  \n",
    "        \n",
    "        log_mel_feat_test = {'X_test_A':X_test_A, 'X_test_B':X_test_B, 'y_test_A':y_test_A, 'y_test_B':y_test_B}\n",
    "        \n",
    "        #print(\"Shape of X_TEST A = \" + str(X_test_A.shape))\n",
    "        #print(\"Shape of X_TEST B = \" + str(X_test_B.shape))\n",
    "\n",
    "        if debug:\n",
    "            print('Bugs test A', bugs_test_A)\n",
    "            print('Bugs test B', bugs_test_B)\n",
    "\n",
    "        \n",
    "        with open(os.path.join(config_DK_AST.dir_out_MED, pickle_name_test), 'wb') as f:\n",
    "            pickle.dump(log_mel_feat_test, f, protocol=4)\n",
    "            print('Saved features to:', os.path.join(config_DK_AST.dir_out_MED, pickle_name_test))\n",
    "    else:\n",
    "        print('Loading test features found at:', os.path.join(config_DK_AST.dir_out_MED, pickle_name_test))\n",
    "        with open(os.path.join(config_DK_AST.dir_out_MED, pickle_name_test), 'rb') as input_file:\n",
    "            log_mel_feat = pickle.load(input_file)\n",
    "\n",
    "            X_test_A = log_mel_feat['X_test_A']\n",
    "            y_test_A = log_mel_feat['y_test_A']\n",
    "            X_test_B = log_mel_feat['X_test_B']\n",
    "            y_test_B = log_mel_feat['y_test_B']\n",
    "\n",
    "\n",
    "    return X_train, y_train, X_test_A, y_test_A, X_test_B, y_test_B\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_test_from_df(df_test_A, df_test_B, debug=False, pickle_name=None):\n",
    "    \n",
    "    if not pickle_name:\n",
    "        pickle_name_test = 'log_mel_feat_test_'+str(config.n_feat)+'_win_'+str(config.win_size)+'_step_'+str(config.win_size)+'_norm_'+str(config.norm_per_sample)+'.pickle'\n",
    "    else:\n",
    "        pickle_name_test = pickle_name\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(config.dir_out_MED, pickle_name_test)):\n",
    "        print('Extracting test features...')\n",
    "\n",
    "        X_test_A, y_test_A, skipped_files_test_A, bugs_test_A = get_feat(data_df= df_test_A, data_dir = config_DK_AST.data_dir,\n",
    "                                                                         rate=config_DK_AST.rate, min_duration=config_DK_AST.min_duration,\n",
    "                                                                         n_feat=config_DK_AST.n_feat,filter_signal = call_filter)\n",
    "        X_test_B, y_test_B, skipped_files_test_B, bugs_test_B = get_feat(data_df= df_test_B, data_dir = config_DK_AST.data_dir,\n",
    "                                                                         rate=config_DK_AST.rate, min_duration=config_DK_AST.min_duration,\n",
    "                                                                         n_feat=config_DK_AST.n_feat,filter_signal = call_filter)\n",
    "        X_test_A, y_test_A = reshape_feat(X_test_A, y_test_A, config_DK_AST.win_size, config_DK_AST.win_size)  # Test should be strided with step = window.\n",
    "        X_test_B, y_test_B = reshape_feat(X_test_B, y_test_B, config_DK_AST.win_size, config_DK_AST.win_size)  \n",
    "        print(\"STANDARDIZATION CAN GO HERE FOR A and B\")\n",
    "        \n",
    "        log_mel_feat_test = {'X_test_A':X_test_A, 'X_test_B':X_test_B, 'y_test_A':y_test_A, 'y_test_B':y_test_B}\n",
    "\n",
    "        if debug:\n",
    "            print('Bugs test A', bugs_test_A)\n",
    "            print('Bugs test B', bugs_test_B)\n",
    "\n",
    "        \n",
    "        with open(os.path.join(config_DK_AST.dir_out_MED, pickle_name_test), 'wb') as f:\n",
    "            pickle.dump(log_mel_feat_test, f)\n",
    "            print('Saved features to:', os.path.join(config_DK_AST.dir_out_MED, pickle_name_test))\n",
    "    else:\n",
    "        print('Loading test features found at:', os.path.join(config_DK_AST.dir_out_MED, pickle_name_test))\n",
    "        with open(os.path.join(config_DK_AST.dir_out_MED, pickle_name_test), 'rb') as input_file:\n",
    "            log_mel_feat = pickle.load(input_file)\n",
    "\n",
    "            X_test_A = log_mel_feat['X_test_A']\n",
    "            y_test_A = log_mel_feat['y_test_A']\n",
    "            X_test_B = log_mel_feat['X_test_B']\n",
    "            y_test_B = log_mel_feat['y_test_B']\n",
    "\n",
    "\n",
    "    return X_test_A, y_test_A, X_test_B, y_test_B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab1f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below applies a band pass filter\n",
    "def create_filter(file , lower_bnd = 300 , upper_bnd = 1000 ,samprate = config_DK_AST.rate , transw = .1 , plot_spec = False, save = False):\n",
    "    samples, sample_rate = librosa.load(file, sr=None)\n",
    "    aud_durn = librosa.get_duration(filename = file)\n",
    "    \n",
    "    lower_bnd = lower_bnd # Hz\n",
    "    upper_bnd = upper_bnd # Hz\n",
    "    transw = .1\n",
    "    samprate = config_DK_AST.rate\n",
    "    N = samprate*aud_durn\n",
    "    ord_param = 30\n",
    "    # noise is the original sound file\n",
    "    noise = samples\n",
    "    timevec = np.arange(0,len(noise))/samprate\n",
    "    # the better way to filter...\n",
    "    \n",
    "    ### first apply a high-pass filter\n",
    "\n",
    "    forder = int(ord_param*samprate/lower_bnd)+1\n",
    "    filtkern = signal.firwin(forder,lower_bnd,pass_zero=False,fs=samprate)\n",
    "    # spectrum of kernel\n",
    "    hz = np.linspace(0,samprate/2,int(np.floor(len(filtkern)/2)+1))\n",
    "    filterpow = np.abs(scipy.fftpack.fft(filtkern))**2\n",
    "    plt.plot(hz,filterpow[:len(hz)],'k')\n",
    "    \n",
    "    # zero-phase-shift filter with reflection\n",
    "    fnoise = signal.filtfilt(filtkern,1,noise)\n",
    "    ### repeat for low-pass filter\n",
    "    forder = int(ord_param*samprate/upper_bnd)+1\n",
    "    filtkern = signal.firwin(forder,upper_bnd,fs=samprate,pass_zero=True)\n",
    "    \n",
    "    # spectrum of kernel\n",
    "    hz = np.linspace(0,samprate/2,int(np.floor(len(filtkern)/2)+1))\n",
    "    filterpow = np.abs(scipy.fftpack.fft(filtkern))**2\n",
    "    ## now filter the filtered signal\n",
    "    fnoise = signal.filtfilt(filtkern,1,fnoise)\n",
    "    \n",
    "    # if we want to save the filtered file\n",
    "    if save == True:\n",
    "        import soundfile as sf\n",
    "        new_name = file + \"filt\" + \".wav\"\n",
    "        sf.write(new_name, fnoise, samplerate = samprate)\n",
    "      \n",
    "    \n",
    "    # the below code will run if the plot argument is true while calling the function\n",
    "    if plot_spec == True:\n",
    "        plotcurves(hz = hz ,lower_bnd = lower_bnd, upper_bnd = upper_bnd,timevec = timevec,noise = noise)\n",
    "        print(\"Spectrogram of filtered signal is ....\")\n",
    "        plot_specgram(y = fnoise)\n",
    "        \n",
    "    return(fnoise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703659d",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482e607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader_ast(x_train, y_train, x_val=None, y_val=None, shuffle=True, n_channels=1):\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.tensor(y_train).float()\n",
    "    \n",
    "    if n_channels == 3:\n",
    "        x_train = x_train.repeat(1,3,1,1)  # Repeat across 3 channels to match ResNet pre-trained model expectation\n",
    "    \n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config_pytorch.batch_size, shuffle=shuffle,pin_memory = True)\n",
    "    \n",
    "    mean=[]\n",
    "    std=[]\n",
    "    \n",
    "    \"\"\"\"\"for i, (x_tr, y_tr) in enumerate(train_loader):\n",
    "        cur_mean = torch.mean(x_tr)\n",
    "        cur_std = torch.std(x_tr)\n",
    "        mean.append(cur_mean)\n",
    "        std.append(cur_std)\n",
    "        #print(cur_mean, cur_std)\"\"\"\n",
    "    \n",
    "    \n",
    "    train_data_mean = np.mean(mean)\n",
    "    train_data_sd = np.mean(std)\n",
    "    #print(\"Inside the dataloader. Modifying the global var for train data mean and std dev.\")\n",
    "    #print(\"The mean of the training data = \" + str(train_data_mean))\n",
    "    #print(\"The SD of the training data = \" + str(train_data_sd))\n",
    "\n",
    "    \n",
    "    if x_val is not None:\n",
    "        x_val = torch.tensor(x_val).float()\n",
    "        if n_channels == 3:\n",
    "            x_val = x_val.repeat(1,3,1,1)\n",
    "        y_val = torch.tensor(y_val).float()\n",
    "        val_dataset = TensorDataset(x_val, y_val)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config_pytorch.batch_size, shuffle=shuffle,pin_memory = True)\n",
    "\n",
    "        return train_loader, val_loader\n",
    "    return train_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8ca2ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=24\n"
     ]
    }
   ],
   "source": [
    "def train_model_ast(x_train, y_train, x_val=None, y_val=None, model = ASTModel()):\n",
    "    \n",
    "    \n",
    "    if x_val is not None:  # TODO: check dimensions when supplying validation data.\n",
    "        train_loader, val_loader = build_dataloader_ast(x_train, y_train, x_val, y_val, n_channels = model.n_channels)\n",
    "    \n",
    "    else:\n",
    "        train_loader = build_dataloader_ast(x_train, y_train, n_channels = model.n_channels)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    print(\"Model Device= \" +str(next(model.parameters()).is_cuda))\n",
    "\n",
    "    # Change compatibility to other loss function, cross-test with main.\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.Adam(model.parameters(), lr=config_pytorch.lr)\n",
    "    #print(\"Optim Device= \" +str(optimiser.device))\n",
    "    \n",
    "\n",
    "    all_train_loss = []\n",
    "    all_train_acc = []\n",
    "    all_val_loss = []\n",
    "    all_val_acc = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_acc = -np.inf\n",
    "\n",
    "    # best_train_loss = np.inf\n",
    "    best_train_acc = -np.inf\n",
    "\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "\n",
    "    for e in range(config_pytorch.epochs):\n",
    "        train_loss = 0.0\n",
    "        model.to(device).train()\n",
    "\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        \n",
    "        for idx,(x,labels) in enumerate(train_loader):\n",
    "            # The model needs input in the form of(batchsize, time, freq . Reshaping the features below)           \n",
    "            bat_size = x.shape[0]\n",
    "            time_dim = x.shape[2]\n",
    "            freq_dim = x.shape[3]\n",
    "            #print(\"Freq_dim = \" +str(freq_dim))\n",
    "            #here you'll send it to model \n",
    "            x_reshaped = x.reshape(bat_size,time_dim,freq_dim).float().cuda()\n",
    "            # this is recommended in paper.\n",
    "            #x_reshaped = (x_reshaped - train_data_mean)/(train_data_sd)\n",
    "            y = labels.reshape(-1,1).cuda()\n",
    "            #print(\"Lables = \" +str(y))\n",
    "            #print(\"Shape of Y = \" + str(y.shape))\n",
    "            #print(\"Unsqueeze Y = \" + str(y))\n",
    "            #print(x_reshaped.shape)\n",
    "            \n",
    "            \n",
    "            if len(x) == 1:\n",
    "                x = x[0]\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            x_reshaped.cuda()\n",
    "            #print(\"X_REshaped device = \" +str(x_reshaped.device))\n",
    "            y.cuda()\n",
    "            #print(\"Y device = \" +str(y.device))\n",
    "            \n",
    "            y_pred = model(x_reshaped.to(device).detach())\n",
    "            #print(\"Y Pred Device = \" +str(y_pred.device))\n",
    "            #print(\"Y Pred shape = \" +str(y_pred.shape))\n",
    "            #print(\"Y  shape = \" +str(y.shape))\n",
    "            #print(\"Y_pred = \" + str(y_pred))\n",
    "            #print(\"sigmoid of Y_pred = \" +str(m(y_pred)))\n",
    "                       \n",
    "            loss = criterion(y_pred, y)\n",
    "            #print(\"loss  = \" +str(loss.device))\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            #print(\"Current train loss before adding the loss = \" + str(train_loss))\n",
    "            train_loss += loss.item()\n",
    "            #print(\"train loss - >\" + str(loss.item()))\n",
    "            #print(\"train loss/len(train_loader)-> \" + str(train_loss/len(train_loader)))\n",
    "            all_y.append(y.cpu().detach())\n",
    "            all_y_pred.append(y_pred.cpu().detach())\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "\n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        train_acc = accuracy_score(all_y.numpy(), (all_y_pred.numpy() > 0.5).astype(float))\n",
    "        all_train_acc.append(train_acc)\n",
    "\n",
    "\n",
    "        # Can add more conditions to support loss instead of accuracy. Use *-1 for loss inequality instead of acc\n",
    "        if x_val is not None:\n",
    "            val_loss, val_acc = test_model(model, val_loader, criterion, 0.5, device=device)\n",
    "            all_val_loss.append(val_loss)\n",
    "            all_val_acc.append(val_acc)\n",
    "\n",
    "            acc_metric = val_acc\n",
    "            best_acc_metric = best_val_acc\n",
    "        else:\n",
    "            acc_metric = train_acc\n",
    "            best_acc_metric = best_train_acc\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            # if checkpoint_name is not None:\n",
    "                # os.path.join(os.path.pardir, 'models', 'pytorch', checkpoint_name)\n",
    "\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, 'pytorch', checkpoint_name))\n",
    "            print('Saving model to:', os.path.join(config.model_dir, 'pytorch', checkpoint_name)) \n",
    "            best_epoch = e\n",
    "            best_train_acc = train_acc\n",
    "            best_train_loss = train_loss\n",
    "            if x_val is not None:\n",
    "                best_val_acc = val_acc\n",
    "                best_val_loss = val_loss\n",
    "            overrun_counter = -1\n",
    "\n",
    "        overrun_counter += 1\n",
    "        if x_val is not None:\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train Acc: %.8f, Val Loss: %.8f, Val Acc: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_acc, val_loss/len(val_loader), val_acc,  overrun_counter))\n",
    "        else:\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train Acc: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_acc, overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49d5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, n_samples):\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Evaluating on {device}')\n",
    "    print(\"n_samples = \" +str(n_samples))\n",
    "\n",
    "    \n",
    "    x_test = torch.tensor(X_test).float()\n",
    "    if model.n_channels == 3:\n",
    "        x_test = x_test.repeat(1,3,1,1)\n",
    "\n",
    "    y_test = torch.tensor(y_test).float()\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "        \n",
    "    y_preds_all = np.zeros([n_samples, len(y_test), 2])\n",
    "    model.eval() # Important to not leak info from batch norm layers and cause other issues\n",
    "\n",
    "    for n in range(n_samples):\n",
    "        all_y_pred = []\n",
    "        all_y = []\n",
    "        \n",
    "        for idx,(x, labels ) in enumerate(test_loader):\n",
    "            # The model needs input in the form of(batchsize, time, freq . Reshaping the features below)           \n",
    "            #print(\"bat_size = \" + str(idx))\n",
    "            bat_size = x.shape[0]\n",
    "            time_dim = x.shape[2]\n",
    "            freq_dim = x.shape[3]\n",
    "            #print(\"Freq_dim = \" +str(freq_dim))\n",
    "            #here you'll send it to model \n",
    "            x_reshaped = x.reshape(bat_size,time_dim,freq_dim).float()\n",
    "            #print(\"Reshaped_X shape = \" + str(x_reshaped.shape))\n",
    "            # this is recommended in paper.\n",
    "            #x_reshaped = (x_reshaped - train_data_mean)/(train_data_sd)\n",
    "            y = labels.reshape(-1,1)\n",
    "            #print(\"Lables = \" +str(y))\n",
    "            #print(\"Shape of Y = \" + str(y.shape))\n",
    "            #print(\"Unsqueeze Y = \" + str(y))\n",
    "            #print(x_reshaped.shape)\n",
    "            \n",
    "            x=  x_reshaped.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x).squeeze()\n",
    "            #print(\"Shape of Y_pred = \" + str(y_pred.shape))\n",
    "            all_y.append(y.cpu().detach())\n",
    "\n",
    "            all_y_pred.append(y_pred.cpu().detach())\n",
    "\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        all_y = torch.cat(all_y)\n",
    "\n",
    "        y_preds_all[n,:,1] = np.array(all_y_pred)\n",
    "        y_preds_all[n,:,0] = 1-np.array(all_y_pred) # Check ordering of classes (yes/no)\n",
    "        test_acc = accuracy_score(all_y.numpy(), (all_y_pred.numpy() > 0.5).astype(float))\n",
    "        # print(test_acc)\n",
    "    return y_preds_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9551769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_aggregated(model, X_test, y_test, n_samples):\n",
    "    ''' Generate predictions for VGGish features (Feat. A) rescaled to time window of 1.92 second features (Feat. B)'''\n",
    "    preds_aggregated_by_mean = []\n",
    "    y_aggregated_prediction_by_mean = []\n",
    "    y_target_aggregated = []\n",
    "    \n",
    "    for idx, recording in enumerate(X_test):\n",
    "        n_target_windows = len(recording)//2  # Calculate expected length: discard edge\n",
    "        y_target = np.repeat(y_test[idx],n_target_windows) # Create y array of correct length\n",
    "        preds = evaluate_model(model, recording, np.repeat(y_test[idx],len(recording)),n_samples) # Sample BNN\n",
    "#         preds = np.mean(preds, axis=0) # Average across BNN samples\n",
    "#         print(np.shape(preds))\n",
    "        preds = preds[:,:n_target_windows*2,:] # Discard edge case\n",
    "#         print(np.shape(preds))\n",
    "#         print('reshaping')\n",
    "        preds = np.mean(preds.reshape(len(preds),-1,2,2), axis=2) # Average every 2 elements, keep samples in first dim\n",
    "#         print(np.shape(preds))\n",
    "        preds_y = np.argmax(preds)  # Append argmax prediction (label output)\n",
    "        y_aggregated_prediction_by_mean.append(preds_y)\n",
    "        preds_aggregated_by_mean.append(preds)  # Append prob (or log-prob/other space)\n",
    "        y_target_aggregated.append(y_target)  # Append y_target\n",
    "#     return preds_aggregated_by_mean, y_aggregated_prediction_by_mean, y_target_aggregated\n",
    "    return np.hstack(preds_aggregated_by_mean), np.concatenate(y_target_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab54d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed6871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f75f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e67eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, class_threshold=0.5, device=None):\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        for idx,(x,labels) in enumerate(test_loader):\n",
    "            bat_size = x.shape[0]\n",
    "            #print(\"bat_size->\" + str(bat_size))\n",
    "            time_dim = x.shape[2]\n",
    "            freq_dim = x.shape[3]\n",
    "            #print(\"time_dim = \" +str(time_dim))\n",
    "            #print(\"Freq_dim = \" +str(freq_dim))\n",
    "            #here you'll send it to model \n",
    "            x_reshaped = x.reshape(bat_size,time_dim,freq_dim).float().cuda()\n",
    "            #Doing the same standardization on the test data\n",
    "            #x_reshaped = (x_reshaped - train_data_mean)/(train_data_sd)\n",
    "            \n",
    "            y = labels.reshape(-1,1).cuda()\n",
    "                      \n",
    "            \n",
    "            y_pred = y_pred = model(x_reshaped.to(device).detach())\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            all_y.append(y.cpu().detach())\n",
    "            all_y_pred.append(y_pred.cpu().detach())\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "            \n",
    "            counter +=1\n",
    "\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_acc = accuracy_score(all_y.numpy(), (all_y_pred.numpy() > class_threshold).astype(float))\n",
    "    \n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505f9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0051f70a",
   "metadata": {},
   "source": [
    "## Loading DATA and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd249f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = 'PyTorch'\n",
    "\n",
    "if library == 'PyTorch':\n",
    "    from PyTorch.runTorch_AST_DK import (ASTModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a29e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config_DK_AST.data_df)\n",
    "\n",
    "# To be kept: please do not edit the test set: these paths select test set A, test set B as described in the paper\n",
    "idx_test_A = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'field')\n",
    "idx_test_B = np.logical_and(df['country'] == 'UK', df['location_type'] == 'culture')\n",
    "idx_train = np.logical_not(np.logical_or(idx_test_A, idx_test_B))\n",
    "df_test_A = df[idx_test_A]\n",
    "df_test_B = df[idx_test_B]\n",
    "\n",
    "\n",
    "df_train = df[idx_train]\n",
    "\n",
    "# Modify by addition or sub-sampling of df_train here\n",
    "# df_train ... \n",
    "\n",
    "# Assertion to check that train does NOT appear in test:\n",
    "assert len(np.where(pd.concat([df_train,df_test_A,\n",
    "                               df_test_B]).duplicated())[0]) == 0, 'Train dataframe contains overlap with Test A, Test B'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce9dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle_name_train = log_mel_feat_train_AST128_win_30_step_5_norm_True.pickle\n",
      "pickle_name_test = log_mel_feat_test_AST128_win_30_step_30_norm_True.pickle\n",
      "Inside if...when pickle file is not found\n",
      "Extracting training features...\n",
      "data_dir = ../data/audio\n",
      "rate = 16000\n",
      "min_duration = 0.96\n",
      "n_feat = 128\n",
      "Completed 100 of 7934\n",
      "Completed 200 of 7934\n",
      "Completed 300 of 7934\n",
      "Completed 400 of 7934\n",
      "Completed 500 of 7934\n",
      "Completed 600 of 7934\n",
      "Completed 700 of 7934\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test_A, y_test_A, X_test_B, y_test_B = get_train_test_from_df(df_train, df_test_A, df_test_B, debug=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a096405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe3767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THE LINE BELOW IF YOU WANT TO TRAIN THE MODEL\n",
    "\n",
    "model = train_model_ast(X_train, y_train, X_val, y_val, model=ASTModel())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66721d79",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model=ASTModel()):\n",
    "    # Instantiate model to inspect\n",
    "    print(\"Filepath = \" + str(filepath))\n",
    "    print(\"model = \" +str(model))\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae24e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp = MLP()\n",
    "#mlp.load_state_dict(torch.load(save_path))\n",
    "\n",
    "\n",
    "model_init=ASTModel()\n",
    "model_init.eval()\n",
    "path = '../outputs/models/pytorch/'\n",
    "model_name = 'model_e2_2022_02_14_21_57_53.pth'\n",
    "\n",
    "\n",
    "#checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "trained_model = load_model(path + model_name , model = model_init)\n",
    "\n",
    "\n",
    "# Dummy data for evaluation\n",
    "\n",
    "#creating random data to test \n",
    "#f1 = np.random.randn(128,1075)\n",
    "#f2 = np.random.randn(128,242)\n",
    "#f3 = np.random.randn(128,234)\n",
    "#f4 = np.ranadom.randn(128,263)\n",
    "\n",
    "# replicates get_feat\n",
    "#feats = [f1,f2,f3,f4]\n",
    "#labels = [0,1,0,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8dd0a",
   "metadata": {},
   "source": [
    "## TEST A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_type = 'FeatA'\n",
    "if feat_type == 'FeatA':\n",
    "    p, yt = evaluate_model_aggregated(model, X_test_A, y_test_A, 30)  # Aggregate windows from feature list (0.96->1.92 s)\n",
    "    PE, MI, log_prob = get_results(p, yt, filename = feat_type + '_' + model_name +'_Test_A')\n",
    "elif feat_type == 'FeatB':\n",
    "    y_preds_all = evaluate_model(model, X_test_A, y_test_A, 30)  # Predict directly over feature windows (1.92 s)\n",
    "    PE, MI, log_prob = get_results(y_preds_all, y_test_A, filename = feat_type + '_' + model_name +'_Test_A')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec2c819",
   "metadata": {},
   "source": [
    "## TEST B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_type = 'FeatB'\n",
    "if feat_type == 'FeatA':\n",
    "    \n",
    "    p, yt = evaluate_model_aggregated(model, X_test_B, y_test_B, 30)  # Aggregate windows from feature list (0.96->1.92 s)\n",
    "    PE, MI, log_prob = get_results(p, yt, filename = feat_type + '_' + model_name +'_Test_B')\n",
    "elif feat_type == 'FeatB':\n",
    "    y_preds_all = evaluate_model(trained_model, X_test_B, y_test_B, 30)  # Predict directly over feature windows (1.92 s)\n",
    "    PE, MI, log_prob = get_results(y_preds_all, y_test_B, filename = feat_type + '_' + model_name +'_Test_B')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035b357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed6225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85ecb92a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf04886f",
   "metadata": {},
   "source": [
    "## TEST SECTION-->use for Test data(Synthetic) creation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating random data to test \n",
    "# This code below replicates get feat\n",
    "f1 = np.random.randn(128,1075)\n",
    "f2 = np.random.randn(128,242)\n",
    "f3 = np.random.randn(128,234)\n",
    "f4 = np.random.randn(128,263)\n",
    "\n",
    "feats = [f1,f2,f3,f4]\n",
    "labels = [0,1,0,1]\n",
    "type(feats)\n",
    "sum_all = 0\n",
    "feats_windowed_array = []\n",
    "labels_windowed_array = []\n",
    "for idx, feat in enumerate(feats):\n",
    "    print(\"idx = \" + str(idx))\n",
    "    print(\"shape of feat = \" + str(np.shape(feat)))\n",
    "    print(\"current sum of array elem = \" + str(np.sum(feat)))\n",
    "    sum_all += np.sum(feat)\n",
    "    print(\"Running/Global Sum =  \" + str((sum_all)))\n",
    "    \n",
    "    \n",
    "    if np.shape(feat)[1] < 30:\n",
    "        print('Length of recording shorter than supplied window size.') \n",
    "        pass\n",
    "    else:\n",
    "        #create a window\n",
    "        feats_windowed = skimage.util.view_as_windows(feat.T, (30,np.shape(feat)[0]), step=5)\n",
    "        labels_windowed = np.full(len(feats_windowed), labels[idx])\n",
    "        feats_windowed_array.append(feats_windowed)\n",
    "        labels_windowed_array.append(labels_windowed)\n",
    "          \n",
    "    #numpy.vstack() function is used to stack the sequence of input arrays vertically to make a single array.\n",
    "    print(\"Length of Feat windowed arraay = \" + str(len(feats_windowed_array)))\n",
    "    #print(\"Mean of features = \" + str(mean(feats_windowed_array)))\n",
    "    print(\"Std Deviation of features = \")\n",
    "features =  np.vstack(feats_windowed_array)\n",
    "lbl = np.hstack(labels_windowed_array)\n",
    "\n",
    "x_tr , y_tr = features , lbl\n",
    "\n",
    "print(\"Shape of x_tr = \" + str(x_tr.shape))\n",
    "print(\"Shape of y_tr = \" + str(y_tr.shape))\n",
    "\n",
    "num_elem = int(x_tr.shape[0])\n",
    "print(\"num_spec = \" + str(num_elem))\n",
    "ldr = build_dataloader_ast(x_tr , y_tr)\n",
    "mean=[]\n",
    "std=[]\n",
    "for i, (x_tr, y_tr) in enumerate(ldr):\n",
    "    \n",
    "    cur_mean = torch.mean(x_tr)\n",
    "    cur_std = torch.std(x_tr)\n",
    "    mean.append(cur_mean)\n",
    "    std.append(cur_std)\n",
    "    print(cur_mean, cur_std)\n",
    "print(np.mean(mean), np.mean(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c92a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
