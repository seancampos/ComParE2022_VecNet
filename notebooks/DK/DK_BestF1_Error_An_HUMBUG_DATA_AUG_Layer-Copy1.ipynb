{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c249c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce91f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 14px;\n",
       "</style>\n",
       "CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dc26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2388dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_1.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_2.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_3.zip?download=1\n",
    "# !wget https://zenodo.org/record/4904800/files/humbugdb_neurips_2021_4.zip?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33e8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip /content/humbugdb_neurips_2021_1.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_2.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_3.zip?download=1 -d '/content/HumBugDB/data/audio'\n",
    "# !unzip /content/humbugdb_neurips_2021_4.zip?download=1 -d '/content/HumBugDB/data/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333eaf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch_audiomentations in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.11.0+cu113)\n",
      "Requirement already satisfied: torchaudio>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.11.0+cu113)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (1.2.2)\n",
      "Requirement already satisfied: librosa>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.8.1)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in /opt/conda/lib/python3.8/site-packages (from torch_audiomentations) (0.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (21.3)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (2.1.9)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.24.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (5.1.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.53.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.6.3)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (1.5.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa>=0.6.0->torch_audiomentations) (0.2.2)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa>=0.6.0->torch_audiomentations) (59.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->librosa>=0.6.0->torch_audiomentations) (3.0.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.26.0)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.4.4)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.8/site-packages (from resampy>=0.2.2->librosa>=0.6.0->torch_audiomentations) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.0->torch_audiomentations) (3.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.0->torch_audiomentations) (2.21)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.0->torch_audiomentations) (4.0.1)\n",
      "Requirement already satisfied: primePy>=1.3 in /opt/conda/lib/python3.8/site-packages (from torch-pitch-shift>=1.2.2->torch_audiomentations) (1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa>=0.6.0->torch_audiomentations) (3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.6.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.21.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (4.28.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (59.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_audiomentations\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffee037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_audiomentations import Compose,AddBackgroundNoise , AddColoredNoise , ApplyImpulseResponse,PeakNormalization,TimeInversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5060bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to find the right version of pytorch with the widget here https://pytorch.org/\n",
    "# I *think* this will work with AWS\n",
    "#!pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b3fdcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other dependencies\n",
    "#!pip install timm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bb1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "#!pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda3b8c4",
   "metadata": {},
   "source": [
    "### 1 Import the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd9b0a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785d89c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/ComParE2022_VecNet/notebooks/DK\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b440c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug main imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../src'))\n",
    "import config ,config_pytorch\n",
    "from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb509df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "#from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063e7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob\n",
    "from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "000c1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd186cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8947d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a4066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "USE_SHORT_AUDIO = True\n",
    "num_workers=8\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    batch_size = 4\n",
    "    test_batch_size = 4\n",
    "    num_workers=1\n",
    "    \n",
    "     \n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48563492",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4a379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "969bcd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates 1.92 secs rows of audio in a data frame format\n",
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    for _,row in df.iterrows():\n",
    "        if row['length'] > min_length:\n",
    "            step_size = step_frac*min_length\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0, 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "            for i in range(1, int((row['length']-min_length)//step_size)):\n",
    "                audio_offsets.append({'id': row['id'], 'offset':int(min_length+(i*step_size)*config.rate), 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "        elif short_audio:\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "    return pd.DataFrame(audio_offsets)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3e5111",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90971a9f",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72095a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>8/9/2016 8:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>1/7/2018 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5      8/9/2016 8:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  1/7/2018 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  1/7/2018 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    df = pd.read_csv(config.data_df_msc_test)\n",
    "else:\n",
    "    df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38007401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d126b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "# other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "# df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a96af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['specie_ind'] == \"NULL_VAL\"].index, inplace=True)\n",
    "#other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "#df.loc[other_df_ind,'specie_ind']= other_ind        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6782d",
   "metadata": {},
   "source": [
    "At this stage we have all extracted the data with specie information and have encoded the specie encoding in a col = 'specie_ind'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be1b360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the TZ and Cup data- this is as per the humbug paper\n",
    "\n",
    "idx_multiclass = np.logical_and(df['country'] == 'Tanzania', df['location_type'] == 'cup')\n",
    "df_all = df[idx_multiclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5df07fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e54c49f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1879</td>\n",
       "      <td>221103</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_24_664.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>221111</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1881</td>\n",
       "      <td>221110</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_25_665.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ma africanus</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1882</td>\n",
       "      <td>221149</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1883</td>\n",
       "      <td>221150</td>\n",
       "      <td>2.56</td>\n",
       "      <td>IFA_17_26_666.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>30-01-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an arabiensis</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>4546</td>\n",
       "      <td>222615</td>\n",
       "      <td>30.72</td>\n",
       "      <td>IFA_86_39_3439.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>4547</td>\n",
       "      <td>222585</td>\n",
       "      <td>25.60</td>\n",
       "      <td>IFA_86_40_3440.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>4548</td>\n",
       "      <td>222586</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_10_3450.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>4549</td>\n",
       "      <td>222596</td>\n",
       "      <td>40.90</td>\n",
       "      <td>IFA_87_11_3451.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>4550</td>\n",
       "      <td>222614</td>\n",
       "      <td>38.40</td>\n",
       "      <td>IFA_87_12_3452.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>23-08-20 00:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an funestus ss</td>\n",
       "      <td>Female</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LT</td>\n",
       "      <td>telinga</td>\n",
       "      <td>tascam</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>Kilombero District</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>Ifakara</td>\n",
       "      <td>cup</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2288 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      id  length                name  sample_rate record_datetime  \\\n",
       "0      1879  221103    2.56   IFA_17_24_664.wav        44100  30-01-20 00:00   \n",
       "1      1880  221111    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "2      1881  221110    2.56   IFA_17_25_665.wav        44100  30-01-20 00:00   \n",
       "3      1882  221149    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "4      1883  221150    2.56   IFA_17_26_666.wav        44100  30-01-20 00:00   \n",
       "...     ...     ...     ...                 ...          ...             ...   \n",
       "2283   4546  222615   30.72  IFA_86_39_3439.wav        44100  23-08-20 00:00   \n",
       "2284   4547  222585   25.60  IFA_86_40_3440.wav        44100  23-08-20 00:00   \n",
       "2285   4548  222586   40.90  IFA_87_10_3450.wav        44100  23-08-20 00:00   \n",
       "2286   4549  222596   40.90  IFA_87_11_3451.wav        44100  23-08-20 00:00   \n",
       "2287   4550  222614   38.40  IFA_87_12_3452.wav        44100  23-08-20 00:00   \n",
       "\n",
       "     sound_type         species  gender fed  ... age  method mic_type  \\\n",
       "0      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "1      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "2      mosquito    ma africanus  Female   f  ... NaN     HBN  telinga   \n",
       "3      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "4      mosquito   an arabiensis  Female   f  ... NaN     HBN  telinga   \n",
       "...         ...             ...     ...  ..  ...  ..     ...      ...   \n",
       "2283   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2284   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2285   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2286   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "2287   mosquito  an funestus ss  Female   f  ... NaN      LT  telinga   \n",
       "\n",
       "     device_type   country            district  province    place  \\\n",
       "0         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "1         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "3         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "4         tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "...          ...       ...                 ...       ...      ...   \n",
       "2283      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2284      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2285      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2286      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "2287      tascam  Tanzania  Kilombero District  Morogoro  Ifakara   \n",
       "\n",
       "     location_type specie_ind  \n",
       "0              cup          7  \n",
       "1              cup          7  \n",
       "2              cup          7  \n",
       "3              cup          0  \n",
       "4              cup          0  \n",
       "...            ...        ...  \n",
       "2283           cup          3  \n",
       "2284           cup          3  \n",
       "2285           cup          3  \n",
       "2286           cup          3  \n",
       "2287           cup          3  \n",
       "\n",
       "[2288 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a571ab3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59962ddb",
   "metadata": {},
   "source": [
    "### Train-Test split( avoiding sklearn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d96cefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_test = np.random.rand(len(df_all)) < 0.2\n",
    "df_test = df_all[msk_test]\n",
    "df_train_temp  = df_all[~msk_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "msk_train = np.random.rand(len(df_train_temp)) < 0.2\n",
    "df_val = df_train_temp[msk_train]\n",
    "df_train  = df_train_temp[~msk_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba5630",
   "metadata": {},
   "source": [
    "## Let's verify for data leakage by performing an inner-join on id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e3dbfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_train, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01ccee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54122489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>length_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>sample_rate_x</th>\n",
       "      <th>record_datetime_x</th>\n",
       "      <th>sound_type_x</th>\n",
       "      <th>species_x</th>\n",
       "      <th>gender_x</th>\n",
       "      <th>fed_x</th>\n",
       "      <th>...</th>\n",
       "      <th>age_y</th>\n",
       "      <th>method_y</th>\n",
       "      <th>mic_type_y</th>\n",
       "      <th>device_type_y</th>\n",
       "      <th>country_y</th>\n",
       "      <th>district_y</th>\n",
       "      <th>province_y</th>\n",
       "      <th>place_y</th>\n",
       "      <th>location_type_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, length_x, name_x, sample_rate_x, record_datetime_x, sound_type_x, species_x, gender_x, fed_x, plurality_x, age_x, method_x, mic_type_x, device_type_x, country_x, district_x, province_x, place_x, location_type_x, specie_ind_x, index_y, length_y, name_y, sample_rate_y, record_datetime_y, sound_type_y, species_y, gender_y, fed_y, plurality_y, age_y, method_y, mic_type_y, device_type_y, country_y, district_y, province_y, place_y, location_type_y, specie_ind_y]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 41 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train,df_val, on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95a6b5",
   "metadata": {},
   "source": [
    "We've confirmed that there is no recording that is common in Train,Test,val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccabb681",
   "metadata": {},
   "source": [
    "### Next, we perform \"offsets\", spliting each(long) recording into multiple 1.92 secs chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7631a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_offset = get_offsets_df(df_train, short_audio=USE_SHORT_AUDIO)\n",
    "df_test_offset = get_offsets_df(df_test, short_audio=USE_SHORT_AUDIO)\n",
    "df_val_offset = get_offsets_df(df_val, short_audio=USE_SHORT_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b18ea9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train offset = 32239\n",
      "length of test offset = 10087\n",
      "length of val offset = 8692\n"
     ]
    }
   ],
   "source": [
    "print(\"length of train offset = \" +str(len(df_train_offset)))\n",
    "print(\"length of test offset = \" +str(len(df_test_offset)))\n",
    "print(\"length of val offset = \" +str(len(df_val_offset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e8c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e10d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c17477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abac730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True)\n",
    "df_test_offset.reset_index(inplace = True)\n",
    "df_val_offset.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e9517",
   "metadata": {},
   "source": [
    "### Let's check for data leakage in offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fe48c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_test_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daf95153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_train_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1421da66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>id</th>\n",
       "      <th>offset_x</th>\n",
       "      <th>length_x</th>\n",
       "      <th>specie_ind_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>offset_y</th>\n",
       "      <th>length_y</th>\n",
       "      <th>specie_ind_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index_x, id, offset_x, length_x, specie_ind_x, index_y, offset_y, length_y, specie_ind_y]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_test_offset , df_val_offset , on = 'id', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed5a7b",
   "metadata": {},
   "source": [
    "### At this stage we've a dataframe of recordin ids and each row corresponds to a 1.92 secs recording or shorter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f44a52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    \"\"\"This function takes a dataframe and provides a count of each specie class\"\"\"\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3134083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32298429 0.56615271 3.6109991  0.61779473 1.98809817 4.24197368\n",
      " 3.08802682 5.57382434]\n"
     ]
    }
   ],
   "source": [
    "#Class imbalance \n",
    "np.array(df_train_offset.specie_ind)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(np.array(df_train_offset.specie_ind)),y=np.array(np.array(df_train_offset.specie_ind)))\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a7ddad",
   "metadata": {},
   "source": [
    "Let us now get the class distribution for each of the dataframes- train,test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2244a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = train\n",
      "i = 0\n",
      "12477\n",
      "DF type = train\n",
      "i = 1\n",
      "7118\n",
      "DF type = train\n",
      "i = 2\n",
      "1116\n",
      "DF type = train\n",
      "i = 3\n",
      "6523\n",
      "DF type = train\n",
      "i = 4\n",
      "2027\n",
      "DF type = train\n",
      "i = 5\n",
      "950\n",
      "DF type = train\n",
      "i = 6\n",
      "1305\n",
      "DF type = train\n",
      "i = 7\n",
      "723\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_train_offset , classes , type_df = \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d3c8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = Val\n",
      "i = 0\n",
      "3613\n",
      "DF type = Val\n",
      "i = 1\n",
      "1994\n",
      "DF type = Val\n",
      "i = 2\n",
      "230\n",
      "DF type = Val\n",
      "i = 3\n",
      "1855\n",
      "DF type = Val\n",
      "i = 4\n",
      "280\n",
      "DF type = Val\n",
      "i = 5\n",
      "228\n",
      "DF type = Val\n",
      "i = 6\n",
      "426\n",
      "DF type = Val\n",
      "i = 7\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_val_offset , classes , type_df = \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2610fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = test\n",
      "i = 0\n",
      "4356\n",
      "DF type = test\n",
      "i = 1\n",
      "1879\n",
      "DF type = test\n",
      "i = 2\n",
      "439\n",
      "DF type = test\n",
      "i = 3\n",
      "1959\n",
      "DF type = test\n",
      "i = 4\n",
      "507\n",
      "DF type = test\n",
      "i = 5\n",
      "312\n",
      "DF type = test\n",
      "i = 6\n",
      "441\n",
      "DF type = test\n",
      "i = 7\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "get_specie_distri(df_test_offset , classes , type_df = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27122905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e550154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pads a short-audio tensor with its mean to ensure that it becomes a 1.92 sec long audio equivalent\n",
    "def pad_mean(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    if DEBUG:\n",
    "        print(\"inside padding mean...\")\n",
    "    x_mean = torch.mean(x_temp)\n",
    "    #x_mean.cuda()\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"X_mean = \" + str(x_mean))\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"left_pad shape = \" + str(left_pad.shape))\n",
    "    left_pad_mean_add = left_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"left_pad_mean shape = \" + str(left_pad_mean_add))\n",
    "        print(\"sum of left pad mean add = \" + str(torch.sum(left_pad_mean_add)))\n",
    "    \n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    if DEBUG:\n",
    "        print(\"right_pad shape = \" + str(right_pad.shape))\n",
    "    right_pad_mean_add = right_pad + x_mean\n",
    "    if DEBUG:\n",
    "        print(\"right_pad_mean shape = \" + str(right_pad_mean_add))\n",
    "        print(\"sum of right pad mean add = \"  + str(torch.sum(right_pad_mean_add)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecea7abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e86349c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_hat,y_true,classes):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_hat, y_true ,labels= range(len(classes)))\n",
    "    import seaborn as sns\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cellsplt.xticks(rotation=90)\n",
    "    ax.xaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    ax.xaxis.tick_bottom()\n",
    "    plt.xticks(rotation=90)\n",
    "    ax.set_ylabel('True', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(classes, fontsize = 10)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23205be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b3f8ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the min length based on config params\n",
    "min_length = (config.win_size * config.n_hop) / config.rate\n",
    "min_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5320651",
   "metadata": {},
   "source": [
    "### Class Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ce460b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization():\n",
    "    \"\"\"This class is for normalizing the spectrograms batch by batch. The normalization used is min-max, two modes 'framewise' and 'imagewise' can be selected. In this paper, we found that 'imagewise' normalization works better than 'framewise'\"\"\"\n",
    "    def __init__(self, mode='framewise'):\n",
    "        if mode == 'framewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.max(1, keepdim=True)[0] # Finding max values for each frame\n",
    "                x_min = x.min(1, keepdim=True)[0]  \n",
    "                output = (x-x_min)/(x_max-x_min) # If there is a column with all zero, nan will occur\n",
    "                output[torch.isnan(output)]=0 # Making nan to 0\n",
    "                return output\n",
    "        elif mode == 'imagewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.reshape(size[0], size[1]*size[2]).max(1, keepdim=True)[0]\n",
    "                x_min = x.reshape(size[0], size[1]*size[2]).min(1, keepdim=True)[0]\n",
    "                x_max = x_max.unsqueeze(1) # Make it broadcastable\n",
    "                x_min = x_min.unsqueeze(1) # Make it broadcastable \n",
    "                return (x-x_min)/(x_max-x_min)\n",
    "        else:\n",
    "            print(f'please choose the correct mode')\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9ad207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcen(x, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, training=False):\n",
    "    frames = x.split(1, -2)\n",
    "    m_frames = []\n",
    "    last_state = None\n",
    "    for frame in frames:\n",
    "        if last_state is None:\n",
    "            last_state = s * frame\n",
    "            m_frames.append(last_state)\n",
    "            continue\n",
    "        if training:\n",
    "            m_frame = ((1 - s) * last_state).add_(s * frame)\n",
    "        else:\n",
    "            m_frame = (1 - s) * last_state + s * frame\n",
    "        last_state = m_frame\n",
    "        m_frames.append(m_frame)\n",
    "    M = torch.cat(m_frames, 1)\n",
    "    if training:\n",
    "        pcen_ = (x / (M + eps).pow(alpha) + delta).pow(r) - delta ** r\n",
    "    else:\n",
    "        pcen_ = x.div_(M.add_(eps).pow_(alpha)).add_(delta).pow_(r).sub_(delta ** r)\n",
    "    return pcen_\n",
    "\n",
    "\n",
    "class PCENTransform(nn.Module):\n",
    "\n",
    "    def __init__(self, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, trainable=True):\n",
    "        super().__init__()\n",
    "        if trainable:\n",
    "            self.log_s = nn.Parameter(torch.log(torch.Tensor([s])))\n",
    "            self.log_alpha = nn.Parameter(torch.log(torch.Tensor([alpha])))\n",
    "            self.log_delta = nn.Parameter(torch.log(torch.Tensor([delta])))\n",
    "            self.log_r = nn.Parameter(torch.log(torch.Tensor([r])))\n",
    "        else:\n",
    "            self.s = s\n",
    "            self.alpha = alpha\n",
    "            self.delta = delta\n",
    "            self.r = r\n",
    "        self.eps = eps\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute((0,2,1)).squeeze(dim=1)\n",
    "        if self.trainable:\n",
    "            x = pcen(x, self.eps, torch.exp(self.log_s), torch.exp(self.log_alpha), torch.exp(self.log_delta), torch.exp(self.log_r), self.training and self.trainable)\n",
    "        else:\n",
    "            x = pcen(x, self.eps, self.s, self.alpha, self.delta, self.r, self.training and self.trainable)\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edc38123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>221103</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>221111</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>221110</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>221149</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>221144</td>\n",
       "      <td>0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      id  offset  length  specie_ind\n",
       "0      0  221103       0    2.56           7\n",
       "1      1  221111       0    2.56           7\n",
       "2      2  221110       0    2.56           7\n",
       "3      3  221149       0    2.56           0\n",
       "4      4  221144       0    2.56           1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aeb42f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_df(loader , trained_model, DEBUG = False):\n",
    "    err_dict = {'id': None,\n",
    "               'label': None,\n",
    "               'offset':None,\n",
    "               'y_hat':None}\n",
    "    model = trained_model\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        all_wav_id = []\n",
    "        all_offset = []\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y,offset,wav_id) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                print(\"y = \" + str(y))\n",
    "                print(\"offset = \" + str(offset))\n",
    "                print(\"wav_id = \" + str(wav_id))\n",
    "                \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            y_pred = model(x)['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            all_y.append(y.cpu().detach())\n",
    "            all_wav_id.append(wav_id.cpu().detach())\n",
    "            all_offset.append(offset.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y).numpy()\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        all_wav_id = torch.cat(all_wav_id)\n",
    "        all_offset = torch.cat(all_offset)\n",
    "        \n",
    "        err_dict['id'] = all_wav_id\n",
    "        err_dict['label'] = all_y\n",
    "        err_dict['offset'] = all_offset\n",
    "        err_dict['y_hat'] = all_y_pred\n",
    "        df_err = pd.DataFrame.from_dict(err_dict)\n",
    "        df_err_uniq = df_err[df_err['label']!= df_err['y_hat']]\n",
    "        df_err_uniq.sort_values(by=['id','offset'])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"inside error ....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        #test_loss = test_loss/len(test_loader)\n",
    "        #test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return df_err_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d512584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            y_pred = model(x)['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "    \n",
    "    \n",
    "    return test_loss, test_f1 , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bfd70b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )\n",
    "def train_model(train_loader, val_loader,test_loader, model = None,  classes = classes,class_weights = class_weights,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    loss_scaler = NativeScaler()\n",
    "    global_step = 0\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    weights_adj = torch.tensor(class_weights).type(torch.float).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights_adj)\n",
    "    optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_f1 = []\n",
    "    all_val_loss = []\n",
    "    all_val_f1 = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_f1 = -np.inf\n",
    "    best_train_f1 = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    lr_log = []\n",
    "    for e in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for batch_i, inputs in enumerate(tk0):\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. batch_ind = \" +str(batch_i))\n",
    "            if batch_i % 200 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(batch_i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            x = inputs[0].to(device).float()\n",
    "            y = inputs[1].type(torch.LongTensor).to(device)\n",
    "            global_step += 1\n",
    "            optimiser.zero_grad()\n",
    "            # AMP\n",
    "            with autocast():\n",
    "                y_pred = model(x)['prediction']\n",
    "                preds = torch.argmax(y_pred, axis = 1)\n",
    "                if DEBUG:\n",
    "                    print(\"y_pred  = \" +str(y_pred))\n",
    "                    print(\"preds = \" +str(preds))\n",
    "                loss = criterion(y_pred, y)\n",
    "            loss_scaler(loss, optimiser,parameters=model_parameters(model))\n",
    "            train_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"batch_ind = \" +str(batch_i))\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "                \n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            lr_log.append(optimiser.param_groups[0]['lr'])\n",
    "            tk0.set_postfix(training_loss=(train_loss / (batch_i+1)), lr=optimiser.param_groups[0]['lr'])\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred,preds\n",
    "        \n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_f1 = f1_score(all_y.numpy(), all_y_pred.numpy(),average='weighted')\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_acc))\n",
    "        all_train_f1.append(train_f1)\n",
    "        val_loss, val_f1 , _,_ = test_model(model, val_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"val\")\n",
    "        if DEBUG:\n",
    "            print(\"val F1 = \" + str(val_f1))\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_f1.append(val_f1)\n",
    "        \n",
    "        acc_metric = val_f1\n",
    "        best_acc_metric = best_val_f1\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            overrun_counter = -1\n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir,  checkpoint_name))\n",
    "            print('Saving model to:', os.path.join(config.model_dir,  checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            print(\"********************************\")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion = nn.CrossEntropyLoss(), classes = classes ,device=device, call = \"test\")\n",
    "            # at times output is not getting printed. Could be due to multi threading and hence adding sleep\n",
    "            time.sleep(2)\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "            print(\"********************************\")\n",
    "            time.sleep(2)\n",
    "            plot_confusion_matrix(all_y_pred_test.numpy(), all_y_test.numpy() , classes)\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "            best_epoch = e\n",
    "            best_val_f1 = val_f1\n",
    "            best_val_loss = val_loss\n",
    "            \n",
    "        else:\n",
    "            print(\"..Overrun....no improvement\")\n",
    "            overrun_counter += 1\n",
    "            print('Epoch: %d, Train Loss: %.8f, Train f1: %.8f, Val Loss: %.8f, Val f1: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_f1, val_loss/len(val_loader), val_f1,  overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85198270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_audiomentations import Compose, Gain, PolarityInversion,AddColoredNoise,ApplyImpulseResponse,PeakNormalization\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])\n",
    "\n",
    "\n",
    "# apply_augmentation = Compose(transforms=[AddColoredNoise(p = 1) ,TimeInversion( p = 1) ,PolarityInversion(p = 1)])\n",
    "\n",
    "# #apply_augmentation = Compose(transforms=[PolarityInversion(p=0.5 ,output_type = 'tensor'),AddColoredNoise(), PeakNormalization(apply_to=\"only_too_loud_sounds\"),TimeInversion(output_type = 'tensor')  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0fd337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTrainDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "                   \n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "       # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "            print(\"offset = \" + str(offset))\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adade609",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozErrAnalysisDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            #mu = torch.std_mean(f)[1]\n",
    "            #st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = f.unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'],offset, self.audio_df.loc[idx]['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71b5f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            #mu = torch.std_mean(f)[1]\n",
    "            #st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = f.unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            print(\"offset = \" + str(offset))\n",
    "            print(\"from get_item of train, returning  x of shape = \" +str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "227acf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aug(x,rate):\n",
    "        apply_augmentation = Compose(transforms=[AddColoredNoise(p = .75) ,TimeInversion( p = .75) ,PolarityInversion(p = .25)])\n",
    "        aug_audio = apply_augmentation(x,sample_rate = rate)\n",
    "        return(aug_audio)\n",
    "    \n",
    "\n",
    "class augment_audio(nn.Module):\n",
    "    \"\"\"This is a class to introduce randomness in the data.\n",
    "    We implement it as a layer in the NN to ensure that it learns from the propertis of the data\"\"\"\n",
    "    def __init__(self , trainable = True, sample_rate = config.rate):\n",
    "        super().__init__()\n",
    "        self.trainable = trainable\n",
    "        self.rate = sample_rate\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim = 1)\n",
    "           \n",
    "        if self.trainable:\n",
    "            x = apply_aug(x , self.rate)\n",
    "        else:\n",
    "            x = x\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x.squeeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46eb341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass the pretrained model and make it a binary classification\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, image_size):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=8, in_chans=1, \n",
    "                        drop_path_rate=0.2, global_pool='max',\n",
    "                        drop_rate=0.2)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                           sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size))\n",
    "        self.timeMasking = T.TimeMasking(time_mask_param=int(config.win_size*0.4), iid_masks=True)\n",
    "        self.freqMasking = T.FrequencyMasking(freq_mask_param=int((config.NFFT//4)*0.15), iid_masks=True)\n",
    "        self.norm_layer = Normalization(mode='framewise')\n",
    "        self.pcen_layer = PCENTransform(eps=1e-6, s=0.025, alpha=0.6, delta=0.1, r=0.2, trainable=True)\n",
    "        self.augment_layer = augment_audio(trainable = True, sample_rate = config.rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first compute spectrogram\n",
    "        if DEBUG:\n",
    "            print(\"input shape that goes for augmentation = \" + str(x.squeeze().shape))\n",
    "        spec = self.augment_layer(x.squeeze())\n",
    "        if DEBUG:\n",
    "            print(\"Out put of augment and input shape that goes for STFT = \" + str(spec.shape))\n",
    "        spec = self.spec_layer(x)  # (B, F, T)\n",
    "        # normalize\n",
    "#         spec = spec.transpose(1,2) # (B, T, F)\n",
    "        if DEBUG:\n",
    "            print(\"Out put of STFT and input shape that goes for PCEN = \" + str(spec.shape))\n",
    "        spec = self.pcen_layer(spec)\n",
    "        if DEBUG:\n",
    "            print(\"Out put of PCEN and input shape that goes for NORM = \" + str(spec.shape))\n",
    "        spec = self.norm_layer(spec)\n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"Out put of NORM and input shape that goes for time mask = \" + str(spec.shape))\n",
    "        spec = self.timeMasking(spec)\n",
    "        if DEBUG:\n",
    "            print(\"Out put of timemask and input shape that goes for freq mask = \" + str(spec.shape))\n",
    "        spec = self.freqMasking(spec)\n",
    "\n",
    "        # then size for CNN model\n",
    "        # and create a channel\n",
    "        spec = self.sizer(spec)\n",
    "        x = spec.unsqueeze(1)\n",
    "        # then repeat channels\n",
    "        if DEBUG:\n",
    "            print(\"Final shape that goes to backbone = \" + str(x.shape))\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output = {\"prediction\": pred,\n",
    "                  \"spectrogram\": spec}\n",
    "        #print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b770c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/audio\n"
     ]
    }
   ],
   "source": [
    "print(config.data_dir)\n",
    "train_dataset = MozTrainDataset(df_train_offset,  config.data_dir, min_length , transform = None)\n",
    "val_dataset = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "test_dataset = MozTestDataset(df_test_offset,  config.data_dir, min_length)\n",
    "error_dataset = MozErrAnalysisDataset(df_val_offset,  config.data_dir, min_length = config.min_duration)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, num_workers=num_workers,batch_size = batch_size,shuffle = True\n",
    "    , pin_memory=True )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "error_loader = torch.utils.data.DataLoader(\n",
    "        error_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3987886e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5dc51d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset = 32239\n",
      "Length of train loader = 504\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train dataset = \" +str(len(train_dataset)))\n",
    "print(\"Length of train loader = \" +str(len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4578e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_itr = iter(train_loader)\n",
    "# a,b = train_itr.next()\n",
    "# print(a.shape)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7db49e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spec_layer = features.STFT(n_fft=int(config.NFFT), freq_bins=None, hop_length=int(config.n_hop),\n",
    "#                               window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "#                            sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "# x = spec_layer(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36464465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_mod = Model('convnext_small',224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6422f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mod(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b739fcbe",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "69e2c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate = 8000. Please make sure the sampling rate is correct in order toget a valid freq range\n",
      "STFT kernels created, time used = 0.0812 seconds\n"
     ]
    }
   ],
   "source": [
    "def load_model(filepath, model=Model('convnext_small',224)):\n",
    "    # Instantiate model to inspect\n",
    "    print(\"Filepath = \" + str(filepath))\n",
    "    print(\"model = \" +str(model))\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d4e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate = 8000. Please make sure the sampling rate is correct in order toget a valid freq range\n",
      "STFT kernels created, time used = 0.0825 seconds\n",
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba0f672a9af41ccb99cb871426f22dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0batch = 0 of 504duraation = 0.05728107690811157\n",
      "epoch = 0batch = 200 of 504duraation = 1.9855552911758423\n",
      "epoch = 0batch = 400 of 504duraation = 3.879076906045278\n",
      "Saving model to: ../../models/model_e0_2022_09_29_23_36_41.pth\n",
      "Now printing classification rport... \n",
      "********************************\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.81      0.39      0.52      4356\n",
      "culex pipiens complex       0.67      0.22      0.34      1879\n",
      "           ae aegypti       0.21      0.64      0.32       439\n",
      "       an funestus ss       0.54      0.52      0.53      1959\n",
      "         an squamosus       0.08      0.16      0.10       507\n",
      "          an coustani       0.20      0.31      0.24       312\n",
      "         ma uniformis       0.12      0.31      0.18       441\n",
      "         ma africanus       0.05      0.37      0.09       194\n",
      "\n",
      "             accuracy                           0.37     10087\n",
      "            macro avg       0.33      0.37      0.29     10087\n",
      "         weighted avg       0.60      0.37      0.43     10087\n",
      "\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.93032322, Train f1: 0.28450248, Val Loss: 0.01140369, Val f1: 0.38076482, overrun_counter -1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888839779a0c4311998bbd0dad172db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1batch = 0 of 504duraation = 0.06723672946294149\n"
     ]
    }
   ],
   "source": [
    "model =Model('convnext_small',224)\n",
    "#filepath = \"../../models/model_e0_2022_09_26_19_25_54.pth\"\n",
    "#model_epcoh_15 = load_model(filepath,model)\n",
    "model, lr_log = train_model(train_loader, val_loader, test_loader,model, classes ,class_weights ,num_epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551435ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x,b = torchaudio.load(\"../../data/audio/221529.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_new = MozTestDataset(df_val_offset,  config.data_dir, min_length)\n",
    "val_loader_new = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=2,\n",
    "        num_workers=0, pin_memory=pin_memory  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_iter = iter(val_loader_new)\n",
    "x1,y1 = val_iter.next()\n",
    "print(x1.shape)\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "x_g = x1.to('cuda')\n",
    "model(x_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18566f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_val_offset\n",
    "model = model_epcoh_10\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "for idx,(x,y) in enumerate(val_dataset):\n",
    "    print(idx)\n",
    "    print(y)\n",
    "    x = x.to('cuda').float()\n",
    "    print(\"x shape = \" +str(x.shape))\n",
    "    #x_new = x.unsqueeze(dim = 1)\n",
    "    print(\"x_new shape = \" +str(x_new.shape))\n",
    "    x_new = x.to('cuda')\n",
    "    y_pred = model(x_new)['prediction']\n",
    "    y_pred_cpu = y_pred.cpu().detach()\n",
    "    preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "    df_erroriloc[idx]['y_hat'] = preds\n",
    "    del x_new\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea994689",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,15360)\n",
    "x = x.unsqueeze(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_offset.head()\n",
    "path_temp = \"../data/audio/\"\n",
    "for i,row in df_val_offset.iterrows():\n",
    "    print(\"i = \" +str(i))\n",
    "    print(\"id = \" + str(int(row['id'])))\n",
    "    file = str(int(row['id']))+\".wav\"\n",
    "    print(file)\n",
    "    path = path_temp + file\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "    if inp_rate != config.rate:\n",
    "        import torchaudio.transforms as T\n",
    "        resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "        waveform = resampler(waveform)\n",
    "    if waveform.shape[1] < config.rate*min_length:\n",
    "        #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "        f_out = pad_mean(waveform)\n",
    "    else:\n",
    "        f = waveform[0]\n",
    "        f_out = f.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor(df):\n",
    "    \n",
    "    path_name = \"../data/audio/\"\n",
    "    file = df.loc[idx]['id'])}.wav\")\n",
    "    waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_mean(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            f_out = f.unsqueeze(0)\n",
    "            \n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"\")\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        \n",
    "        if DEBUG:\n",
    "            print(\"shape of x post augmentation = \" + str(x.shape))\n",
    "            \n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        if DEBUG:\n",
    "            print(\"returning x of shape ...\" + str(x[:,offset:int(offset+config.rate*self.min_length)].shape))\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc5dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the model checkpoint as a parameter as input\n",
    "# read the val df\n",
    "#get the tensor rep for the offset.\n",
    "#pass it to the model get add get the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "for i in range(10):\n",
    "    label.append(np.random.rand(9))\n",
    "    pred.append(np.random.rand(9))\n",
    "print(label)\n",
    "print(pred)\n",
    "print(classification_report(label, pred, target_names= classes, labels= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca92e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(8, device = \"cuda\")\n",
    "print(label)\n",
    "label_cpu = label.cpu().detach()\n",
    "print(label_cpu)\n",
    "label_np = label_cpu.numpy()\n",
    "print(type(label_np))\n",
    "label_np_item = label_np.item()\n",
    "print(type(label_np_item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6fbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.randn(4,9)\n",
    "y_pred.shape\n",
    "#y_pred_np = y_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b200bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_np\n",
    "# y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c52001",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840dc426",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928938aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    print(\"idx = \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2d439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68a5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b17db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
