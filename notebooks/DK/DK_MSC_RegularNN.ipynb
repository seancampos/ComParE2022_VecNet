{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daf44b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".CodeMirror{\n",
       "font-size: 14px;\n",
       "</style>\n",
       "CUDA_LAUNCH_BLOCKING=1\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style type='text/css'>\n",
    ".CodeMirror{\n",
    "font-size: 14px;\n",
    "</style>\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4faa21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to find the right version of pytorch with the widget here https://pytorch.org/\n",
    "# I *think* this will work with AWS\n",
    "#!pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124c5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other dependencies\n",
    "#!pip install timm ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe30185",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "#!pip install git+https://github.com/KinWaiCheuk/nnAudio.git#subdirectory=Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea6893",
   "metadata": {},
   "source": [
    "### 1 Import the kitchen sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d056a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=:4096:8\n"
     ]
    }
   ],
   "source": [
    "%env CUBLAS_WORKSPACE_CONFIG=:4096:8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf1dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug main imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../lib'))\n",
    "import config\n",
    "from evaluate import get_results\n",
    "import numpy as np\n",
    "\n",
    "# Troubleshooting and visualisation\n",
    "import IPython.display as ipd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41825f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# humbug lib imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PyTorch import config_pytorch\n",
    "from datetime import datetime\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4773311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional pytorch tools\n",
    "import random\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchvision.transforms as VT\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import timm\n",
    "import timm.optim\n",
    "from timm.loss import BinaryCrossEntropy\n",
    "from timm.utils import NativeScaler\n",
    "from timm.models import model_parameters\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4964308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nnAudio\n",
    "from nnAudio import features\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e471fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Training variables \n",
    "num_workers=4\n",
    "pin_memory=True\n",
    "#train_size = 100\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "DEBUG = False\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454f2e1",
   "metadata": {},
   "source": [
    "### Run all these function definition cells\n",
    "These have been extracted from the lib folder and are here to make them more easily editable.  Most of the action happens in *get_feat_torch*, which does feature extraction and *train_model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7bbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' , 'others']\n",
    "classes_no_other = ['an arabiensis','culex pipiens complex', 'ae aegypti','an funestus ss','an squamosus',\n",
    "               'an coustani','ma uniformis','ma africanus' ]\n",
    "other_ind = classes.index('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4641b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath, model):\n",
    "    # Instantiate model to inspect\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    print(f'Training on {device}')\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "    model = model.to(device)\n",
    "    # Load trained parameters from checkpoint (may need to download from S3 first)\n",
    "\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        map_location=lambda storage, loc: storage.cuda()\n",
    "    else:\n",
    "        map_location='cpu'\n",
    "        \n",
    "    checkpoint = model.load_state_dict(torch.load(filepath))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a9a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, loader, criterion,  classes = classes,device=None , call = \"val\"):\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"calling for ...\" +str(call))\n",
    "    with torch.no_grad():\n",
    "        if device is None:\n",
    "            torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        sigmoid = nn.Sigmoid()\n",
    "        test_loss = 0.0\n",
    "        model.eval()\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        counter = 1\n",
    "        if DEBUG:\n",
    "            print(\"length of loader = \" + str(len(loader)))\n",
    "        for idx,(x,y) in enumerate(loader):\n",
    "            if DEBUG:\n",
    "                print(\"loader index = \" + str(idx))\n",
    "                            \n",
    "            x = x.to(device).float() \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            if DEBUG:\n",
    "                print(\"y = \" + str(y))\n",
    "            y_pred = model(x)['prediction']\n",
    "            preds = torch.argmax(y_pred, axis = 1)\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            if DEBUG:\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"preds = \" +str(preds))\n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "                                   \n",
    "            loss = criterion(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            #all_y_pred.append(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "            \n",
    "            del x\n",
    "            del y\n",
    "            del y_pred\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"inside test....\")\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        test_loss = test_loss/len(test_loader)\n",
    "        test_acc = accuracy_score(all_y.numpy(), all_y_pred.numpy())\n",
    "    \n",
    "    \n",
    "    return test_loss, test_acc , all_y,all_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91109fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, val_loader,test_loader, model = None,  classes = classes,num_epochs = num_epochs ,n_channels = 1):\n",
    "    # Creates a GradScaler once at the beginning of training.\n",
    "    loss_scaler = NativeScaler()\n",
    "    global_step = 0\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Training on {device}')    \n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using data parallel\")\n",
    "        model = nn.DataParallel(model, device_ids=list(range(torch.cuda.device_count())))\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = timm.optim.RAdam(model.parameters(), lr=config_pytorch.lr/10)\n",
    "    num_epochs = num_epochs\n",
    "    all_train_loss = []\n",
    "    all_train_acc = []\n",
    "    all_val_loss = []\n",
    "    all_val_acc = []\n",
    "    best_val_loss = np.inf\n",
    "    best_val_acc = -np.inf\n",
    "    best_train_acc = -np.inf\n",
    "    best_epoch = -1\n",
    "    checkpoint_name = None\n",
    "    overrun_counter = 0\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    lr_log = []\n",
    "    for e in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_y = []\n",
    "        all_y_pred = []\n",
    "        tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "        for batch_i, inputs in enumerate(tk0):\n",
    "            if DEBUG:\n",
    "                print(\"inside train loop.. batch_ind = \" +str(batch_i))\n",
    "            if batch_i % 200 == 0:\n",
    "                bat_time = time.time()\n",
    "                durn = (bat_time - start_time)/60\n",
    "                print(\"epoch = \" +str(e) + \"batch = \" +str(batch_i) + \" of \" + str(len(train_loader)) + \"duraation = \" + str(durn))\n",
    "            x = inputs[0].to(device).float()\n",
    "            y = inputs[1].type(torch.LongTensor).to(device)\n",
    "            global_step += 1\n",
    "            optimiser.zero_grad()\n",
    "            # AMP\n",
    "            with autocast():\n",
    "                y_pred = model(x)['prediction']\n",
    "                preds = torch.argmax(y_pred, axis = 1)\n",
    "                if DEBUG:\n",
    "                    print(\"y_pred  = \" +str(y_pred))\n",
    "                    print(\"preds = \" +str(preds))\n",
    "                loss = criterion(y_pred, y)\n",
    "            loss_scaler(loss, optimiser,parameters=model_parameters(model))\n",
    "            train_loss += loss.item()\n",
    "            all_y.append(y.cpu().detach())\n",
    "            y_pred_cpu = y_pred.cpu().detach()\n",
    "            preds = torch.argmax(y_pred_cpu, axis = 1)\n",
    "            if DEBUG:\n",
    "                print(\"batch_ind = \" +str(batch_i))\n",
    "                print(\"y_pred_cpu = \" + str(y_pred_cpu))\n",
    "                \n",
    "            all_y_pred.append(preds.cpu().detach())\n",
    "            lr_log.append(optimiser.param_groups[0]['lr'])\n",
    "            tk0.set_postfix(training_loss=(train_loss / (batch_i+1)), lr=optimiser.param_groups[0]['lr'])\n",
    "            del x\n",
    "            del y\n",
    "            del y_pred,preds\n",
    "        \n",
    "        all_train_loss.append(train_loss/len(train_loader))\n",
    "        all_y = torch.cat(all_y)\n",
    "        all_y_pred = torch.cat(all_y_pred)\n",
    "        if DEBUG:\n",
    "            print(\"y = \" + str(all_y))\n",
    "            print(\"y_pred  = \" + str(all_y_pred))\n",
    "        \n",
    "        train_acc = accuracy_score(all_y.numpy(), all_y_pred.numpy())\n",
    "        if DEBUG:\n",
    "            print(\"train acc = \" +str(train_acc))\n",
    "        all_train_acc.append(train_acc)\n",
    "        val_loss, val_acc , _,_ = test_model(model, val_loader, criterion, classes = classes ,device=device, call = \"val\")\n",
    "        if DEBUG:\n",
    "            print(\"val accuracy = \" + str(val_acc))\n",
    "        all_val_loss.append(val_loss)\n",
    "        all_val_acc.append(val_acc)\n",
    "        \n",
    "        acc_metric = val_acc\n",
    "        best_acc_metric = best_val_acc\n",
    "        if acc_metric > best_acc_metric:  \n",
    "            checkpoint_name = f'model_e{e}_{datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")}.pth'\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_dir, 'pytorch', checkpoint_name))\n",
    "            print('Saving model to:', os.path.join(config.model_dir, 'pytorch', checkpoint_name)) \n",
    "            print(\"Now printing classification rport... \")\n",
    "            from sklearn.metrics import classification_report\n",
    "            _, _ , all_y_test,all_y_pred_test = test_model(model, test_loader, criterion, classes = classes ,device=device, call = \"test\")\n",
    "            print(classification_report(all_y_test.numpy(), all_y_pred_test.numpy(), target_names= classes))\n",
    "        \n",
    "            best_epoch = e\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            overrun_counter = -1\n",
    "        overrun_counter += 1\n",
    "        print('Epoch: %d, Train Loss: %.8f, Train Acc: %.8f, Val Loss: %.8f, Val Acc: %.8f, overrun_counter %i' % (e, train_loss/len(train_loader), train_acc, val_loss/len(val_loader), val_acc,  overrun_counter))\n",
    "        if overrun_counter > config_pytorch.max_overrun:\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return model, lr_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe278016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offsets_df(df, short_audio=False):\n",
    "    audio_offsets = []\n",
    "    min_length = config.win_size*config.NFFT/(((1/config.n_hop)*config.NFFT)*config.rate)\n",
    "    step_frac = config.step_size/config.win_size\n",
    "    for _,row in df.iterrows():\n",
    "        if row['length'] > min_length:\n",
    "            step_size = step_frac*min_length\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0, 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "            for i in range(1, int((row['length']-min_length)//step_size)):\n",
    "                audio_offsets.append({'id': row['id'], 'offset':int(min_length+(i*step_size)*config.rate), 'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "        elif short_audio:\n",
    "            audio_offsets.append({'id':row['id'], 'offset':0,'length': row['length'],'specie_ind': row['specie_ind']})\n",
    "    return pd.DataFrame(audio_offsets)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaba9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(df_offset, indices):\n",
    "    list_df_ind = []\n",
    "    #print(\"len of indices = \" + str(len(indices)))\n",
    "    for ind in indices :\n",
    "        df_name = \"df_\"+ str(ind)\n",
    "        df_name = df_offset[df_offset['specie_ind'] == ind]\n",
    "        list_df_ind.append(df_name)\n",
    "    df_offset_trimmed = pd.concat(list_df_ind)\n",
    "    return(df_offset_trimmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65fb47ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the min length based on config params\n",
    "min_length = (config.win_size * config.n_hop) / config.rate\n",
    "min_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159bc16b",
   "metadata": {},
   "source": [
    "### 3 The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3bc8ca",
   "metadata": {},
   "source": [
    "### Read CSV and get train/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5282c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "517c43ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>length</th>\n",
       "      <th>name</th>\n",
       "      <th>sample_rate</th>\n",
       "      <th>record_datetime</th>\n",
       "      <th>sound_type</th>\n",
       "      <th>species</th>\n",
       "      <th>gender</th>\n",
       "      <th>fed</th>\n",
       "      <th>plurality</th>\n",
       "      <th>age</th>\n",
       "      <th>method</th>\n",
       "      <th>mic_type</th>\n",
       "      <th>device_type</th>\n",
       "      <th>country</th>\n",
       "      <th>district</th>\n",
       "      <th>province</th>\n",
       "      <th>place</th>\n",
       "      <th>location_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>08-09-16 08:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>08-09-16 08:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>08-09-16 08:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>08-09-16 08:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>CDC_Ae-aegypti_labelled_800.wav</td>\n",
       "      <td>8000</td>\n",
       "      <td>08-09-16 08:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>ae aegypti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Plural</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>phone</td>\n",
       "      <td>Alcatel 4009X</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>CDC insect cultures, Atlanta</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>3562</td>\n",
       "      <td>6.083093</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>01-07-18 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>3556</td>\n",
       "      <td>6.719908</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>01-07-18 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>3553</td>\n",
       "      <td>6.128580</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>01-07-18 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an maculatus</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>3561</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>01-07-18 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9012</th>\n",
       "      <td>3552</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>#988-1001.wav</td>\n",
       "      <td>44100</td>\n",
       "      <td>01-07-18 12:00</td>\n",
       "      <td>mosquito</td>\n",
       "      <td>an harrisoni</td>\n",
       "      <td>Female</td>\n",
       "      <td>t</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABN</td>\n",
       "      <td>telinga</td>\n",
       "      <td>olympus</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Sai Yok District</td>\n",
       "      <td>Kanchanaburi Province</td>\n",
       "      <td>field site near Pu Teuy Village</td>\n",
       "      <td>cup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6008 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     length                             name  sample_rate  \\\n",
       "1       53   0.463456  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "2       57   0.170249  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "3       61   0.104041  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "4       69   0.274290  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "5       56   0.420894  CDC_Ae-aegypti_labelled_800.wav         8000   \n",
       "...    ...        ...                              ...          ...   \n",
       "8999  3562   6.083093                    #988-1001.wav        44100   \n",
       "9000  3556   6.719908                    #988-1001.wav        44100   \n",
       "9009  3553   6.128580                    #988-1001.wav        44100   \n",
       "9011  3561  11.614280                    #988-1001.wav        44100   \n",
       "9012  3552   2.920249                    #988-1001.wav        44100   \n",
       "\n",
       "     record_datetime sound_type       species  gender  fed plurality  age  \\\n",
       "1     08-09-16 08:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "2     08-09-16 08:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "3     08-09-16 08:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "4     08-09-16 08:00   mosquito    ae aegypti     NaN  NaN    Single  NaN   \n",
       "5     08-09-16 08:00   mosquito    ae aegypti     NaN  NaN    Plural  NaN   \n",
       "...              ...        ...           ...     ...  ...       ...  ...   \n",
       "8999  01-07-18 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9000  01-07-18 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9009  01-07-18 12:00   mosquito  an maculatus  Female    t    Single  NaN   \n",
       "9011  01-07-18 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "9012  01-07-18 12:00   mosquito  an harrisoni  Female    t    Single  NaN   \n",
       "\n",
       "     method mic_type    device_type   country          district  \\\n",
       "1       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "2       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "3       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "4       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "5       NaN    phone  Alcatel 4009X       USA           Georgia   \n",
       "...     ...      ...            ...       ...               ...   \n",
       "8999    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9000    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9009    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9011    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "9012    ABN  telinga        olympus  Thailand  Sai Yok District   \n",
       "\n",
       "                   province                            place location_type  \n",
       "1                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "2                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "3                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "4                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "5                   Atlanta     CDC insect cultures, Atlanta       culture  \n",
       "...                     ...                              ...           ...  \n",
       "8999  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9000  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9009  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9011  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "9012  Kanchanaburi Province  field site near Pu Teuy Village           cup  \n",
       "\n",
       "[6008 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    df = pd.read_csv(config.data_df_msc_test)\n",
    "else:\n",
    "    df = pd.read_csv(config.data_df)\n",
    "\n",
    "#df = df.loc[df['Grade'].notnull()]\n",
    "df = df.loc[df['species'].notnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7a3e81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a colum for specie encoding\n",
    "df['specie_ind'] = \"NULL_VAL\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66fd4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specie = an arabiensisand its index = 0\n",
      "specie = culex pipiens complexand its index = 1\n",
      "specie = ae aegyptiand its index = 2\n",
      "specie = an funestus ssand its index = 3\n",
      "specie = an squamosusand its index = 4\n",
      "specie = an coustaniand its index = 5\n",
      "specie = ma uniformisand its index = 6\n",
      "specie = ma africanusand its index = 7\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column to encode specie_index in the same order as the list \"classes\"\n",
    "ind = 0\n",
    "for specie in classes_no_other:\n",
    "    print(\"specie = \" + str(specie) + \"and its index = \" + str(ind) )\n",
    "    row_indexes=df[df['species']==specie].index \n",
    "    df.loc[row_indexes,'specie_ind']= ind\n",
    "    ind+=1\n",
    "\n",
    "    \n",
    "other_df_ind = df[df['specie_ind'] == \"NULL_VAL\"].index\n",
    "df.loc[other_df_ind,'specie_ind']= other_ind                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18dfa0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SHORT_AUDIO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2a599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d72ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_offset = get_offsets_df(df, short_audio=USE_SHORT_AUDIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "782a3ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463456</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104041</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.274290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151807</th>\n",
       "      <td>3561</td>\n",
       "      <td>71681</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151808</th>\n",
       "      <td>3561</td>\n",
       "      <td>74241</td>\n",
       "      <td>11.614280</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151809</th>\n",
       "      <td>3552</td>\n",
       "      <td>0</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151810</th>\n",
       "      <td>3552</td>\n",
       "      <td>2561</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151811</th>\n",
       "      <td>3552</td>\n",
       "      <td>5121</td>\n",
       "      <td>2.920249</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151812 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  offset     length  specie_ind\n",
       "0         53       0   0.463456           2\n",
       "1         57       0   0.170249           2\n",
       "2         61       0   0.104041           2\n",
       "3         69       0   0.274290           2\n",
       "4         56       0   0.420894           2\n",
       "...      ...     ...        ...         ...\n",
       "151807  3561   71681  11.614280           8\n",
       "151808  3561   74241  11.614280           8\n",
       "151809  3552       0   2.920249           8\n",
       "151810  3552    2561   2.920249           8\n",
       "151811  3552    5121   2.920249           8\n",
       "\n",
       "[151812 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb1e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0922ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train_offset_temp,df_test_offset  = train_test_split(df_offset, test_size=0.2)\n",
    "df_train_offset,df_val_offset  = train_test_split(df_train_offset_temp, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b43540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(classes)):\n",
    "#     df_temp = df_val_offset[df_val_offset['specie_ind'] == i]\n",
    "#     print(\"i = \" +str(i))\n",
    "#     print(len(df_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a6bdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp.reset_index(inplace = True)\n",
    "df_train_offset.reset_index(inplace = True)\n",
    "df_test_offset.reset_index(inplace = True)\n",
    "df_val_offset.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "338a2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specie_distri(df , classes , type_df = None):\n",
    "    for i in range(len(classes)):\n",
    "        print(\"DF type = \" + str(type_df))\n",
    "        df_temp = df[df['specie_ind'] == i]\n",
    "        print(\"i = \" +str(i))\n",
    "        print(len(df_temp))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46dccdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24290"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_val_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c74947be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF type = Test\n",
      "i = 0\n",
      "9416\n",
      "DF type = Test\n",
      "i = 1\n",
      "4384\n",
      "DF type = Test\n",
      "i = 2\n",
      "691\n",
      "DF type = Test\n",
      "i = 3\n",
      "4239\n",
      "DF type = Test\n",
      "i = 4\n",
      "1181\n",
      "DF type = Test\n",
      "i = 5\n",
      "592\n",
      "DF type = Test\n",
      "i = 6\n",
      "874\n",
      "DF type = Test\n",
      "i = 7\n",
      "401\n",
      "DF type = Test\n",
      "i = 8\n",
      "8585\n"
     ]
    }
   ],
   "source": [
    "#get_specie_distri(df_train_offset , classes , type_df = \"train\")\n",
    "#get_specie_distri(df_val_offset , classes , type_df = \"Val\")\n",
    "get_specie_distri(df_test_offset , classes , type_df = \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e927a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get the frame offsets for each audio file into dataframes\n",
    "# audio_df_train = get_offsets_df(df_train, short_audio=USE_SHORT_AUDIO)\n",
    "# audio_df_test_A = get_offsets_df(df_test_A, short_audio=False)\n",
    "# audio_df_test_B = get_offsets_df(df_test_B, short_audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c413357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pads a file with 0s to make it a 1.92 sec file\n",
    "def pad_zero(x_temp,rate = config.rate, min_length = config.min_duration ):\n",
    "    #print(\"inside padding zero...\")\n",
    "    left_pad_amt = int((rate*min_length-x_temp.shape[1])//2)\n",
    "    #print(\"left_pad_amt = \" + str(left_pad_amt))\n",
    "    left_pad = torch.zeros(1,left_pad_amt) #+ (0.1**0.5)*torch.randn(1, left_pad_amt)\n",
    "    right_pad_amt = int(rate*min_length-x_temp.shape[1]-left_pad_amt)\n",
    "    right_pad = torch.zeros(1,right_pad_amt)# + (0.1**0.5)*torch.randn(1, right_pad_amt)\n",
    "    f = torch.cat([left_pad,x_temp,right_pad],dim=1)[0]\n",
    "    f = f.unsqueeze(dim = 0)\n",
    "    #print(\"returning a tensor of shape = \" + str(f.shape))\n",
    "    return(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b41e7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalization():\n",
    "    \"\"\"This class is for normalizing the spectrograms batch by batch. The normalization used is min-max, two modes 'framewise' and 'imagewise' can be selected. In this paper, we found that 'imagewise' normalization works better than 'framewise'\"\"\"\n",
    "    def __init__(self, mode='framewise'):\n",
    "        if mode == 'framewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.max(1, keepdim=True)[0] # Finding max values for each frame\n",
    "                x_min = x.min(1, keepdim=True)[0]  \n",
    "                output = (x-x_min)/(x_max-x_min) # If there is a column with all zero, nan will occur\n",
    "                output[torch.isnan(output)]=0 # Making nan to 0\n",
    "                return output\n",
    "        elif mode == 'imagewise':\n",
    "            def normalize(x):\n",
    "                size = x.shape\n",
    "                x_max = x.reshape(size[0], size[1]*size[2]).max(1, keepdim=True)[0]\n",
    "                x_min = x.reshape(size[0], size[1]*size[2]).min(1, keepdim=True)[0]\n",
    "                x_max = x_max.unsqueeze(1) # Make it broadcastable\n",
    "                x_min = x_min.unsqueeze(1) # Make it broadcastable \n",
    "                return (x-x_min)/(x_max-x_min)\n",
    "        else:\n",
    "            print(f'please choose the correct mode')\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.normalize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "469e45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcen(x, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, training=False):\n",
    "    frames = x.split(1, -2)\n",
    "    m_frames = []\n",
    "    last_state = None\n",
    "    for frame in frames:\n",
    "        if last_state is None:\n",
    "            last_state = s * frame\n",
    "            m_frames.append(last_state)\n",
    "            continue\n",
    "        if training:\n",
    "            m_frame = ((1 - s) * last_state).add_(s * frame)\n",
    "        else:\n",
    "            m_frame = (1 - s) * last_state + s * frame\n",
    "        last_state = m_frame\n",
    "        m_frames.append(m_frame)\n",
    "    M = torch.cat(m_frames, 1)\n",
    "    if training:\n",
    "        pcen_ = (x / (M + eps).pow(alpha) + delta).pow(r) - delta ** r\n",
    "    else:\n",
    "        pcen_ = x.div_(M.add_(eps).pow_(alpha)).add_(delta).pow_(r).sub_(delta ** r)\n",
    "    return pcen_\n",
    "\n",
    "\n",
    "class PCENTransform(nn.Module):\n",
    "\n",
    "    def __init__(self, eps=1e-6, s=0.025, alpha=0.98, delta=2, r=0.5, trainable=True):\n",
    "        super().__init__()\n",
    "        if trainable:\n",
    "            self.log_s = nn.Parameter(torch.log(torch.Tensor([s])))\n",
    "            self.log_alpha = nn.Parameter(torch.log(torch.Tensor([alpha])))\n",
    "            self.log_delta = nn.Parameter(torch.log(torch.Tensor([delta])))\n",
    "            self.log_r = nn.Parameter(torch.log(torch.Tensor([r])))\n",
    "        else:\n",
    "            self.s = s\n",
    "            self.alpha = alpha\n",
    "            self.delta = delta\n",
    "            self.r = r\n",
    "        self.eps = eps\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute((0,2,1)).squeeze(dim=1)\n",
    "        if self.trainable:\n",
    "            x = pcen(x, self.eps, torch.exp(self.log_s), torch.exp(self.log_alpha), torch.exp(self.log_delta), torch.exp(self.log_r), self.training and self.trainable)\n",
    "        else:\n",
    "            x = pcen(x, self.eps, self.s, self.alpha, self.delta, self.r, self.training and self.trainable)\n",
    "#         x = x.unsqueeze(dim=1).permute((0,1,3,2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c1d2b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52168</td>\n",
       "      <td>220489</td>\n",
       "      <td>66561</td>\n",
       "      <td>28.10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113652</td>\n",
       "      <td>222318</td>\n",
       "      <td>66561</td>\n",
       "      <td>33.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70368</td>\n",
       "      <td>221598</td>\n",
       "      <td>7681</td>\n",
       "      <td>15.30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21340</td>\n",
       "      <td>221209</td>\n",
       "      <td>20481</td>\n",
       "      <td>20.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44053</td>\n",
       "      <td>220156</td>\n",
       "      <td>10241</td>\n",
       "      <td>35.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      id  offset  length  specie_ind\n",
       "0   52168  220489   66561   28.10           4\n",
       "1  113652  222318   66561   33.22           1\n",
       "2   70368  221598    7681   15.30           3\n",
       "3   21340  221209   20481   20.48           0\n",
       "4   44053  220156   10241   35.78           0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ba059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836350c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b1f8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_df, data_dir, min_length, cache=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            audio_df (DataFrame): from get_offsets_df function \n",
    "            noise_df (DataFrame): the df of noise files and lengths\n",
    "            data_dir (string): Directory with all the wavs.\n",
    "            cache (dict): Empty dictionary used as cache\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.audio_df = audio_df\n",
    "        #self.noise_df = noise_df\n",
    "        self.data_dir = data_dir\n",
    "        self.min_length = min_length\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def _get_sample_(self, path, resample=None):\n",
    "        \n",
    "        waveform, inp_rate = torchaudio.load(path)\n",
    "        \n",
    "        if inp_rate != config.rate:\n",
    "            import torchaudio.transforms as T\n",
    "            resampler = T.Resample(inp_rate, config.rate, dtype=waveform.dtype)\n",
    "            waveform = resampler(waveform)\n",
    "    \n",
    "        \n",
    "        #waveform, rate = torchaudio.load(path)\n",
    "                \n",
    "        if waveform.shape[1] < config.rate*self.min_length:\n",
    "            #r = math.ceil((config.rate*self.min_length)/waveform.shape[1])\n",
    "            f_out = pad_zero(waveform)\n",
    "        else:\n",
    "            f = waveform[0]\n",
    "            mu = torch.std_mean(f)[1]\n",
    "            st = torch.std_mean(f)[0]\n",
    "            # clip amplitudes\n",
    "            f_out = torch.clamp(f, min=mu-st*3, max=mu+st*3).unsqueeze(0)\n",
    "            if self.cache is not None:\n",
    "                self.cache[path] = f_out\n",
    "        return f_out\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #real_idx = idx % len(self.audio_df)\n",
    "        if DEBUG:\n",
    "            print(\"idx = \" + str(idx))\n",
    "        x = self._get_sample_(os.path.join(self.data_dir,f\"{int(self.audio_df.loc[idx]['id'])}.wav\"), resample=config.rate)\n",
    "        \n",
    "        # random noise on even number indexes\n",
    "        offset = int(self.audio_df.loc[idx]['offset'])\n",
    "        \n",
    "        return (x[:,offset:int(offset+config.rate*self.min_length)],self.audio_df.loc[idx]['specie_ind'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5b66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a2a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4629f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass the pretrained model and make it a binary classification\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name, image_size):\n",
    "        super().__init__()\n",
    "        # num_classes=0 removes the pretrained head\n",
    "        self.backbone = timm.create_model(model_name,\n",
    "                        pretrained=True, num_classes=9, in_chans=1, \n",
    "                        drop_path_rate=0.05, global_pool='max',\n",
    "                        drop_rate=0.05)\n",
    "        #####  This section is model specific\n",
    "        #### It freezes some fo the layers by name\n",
    "        #### you'll have to inspect the model to see the names\n",
    "                #### end layer freezing\n",
    "        self.spec_layer = features.STFT(n_fft=config.NFFT, freq_bins=None, hop_length=config.n_hop,\n",
    "                              window='hann', freq_scale='linear', center=True, pad_mode='reflect',\n",
    "                          fmin=400, fmax=2000, sr=config.rate, output_format=\"Magnitude\", trainable=True,)\n",
    "        self.out = nn.Linear(self.backbone.num_features, 1)\n",
    "        self.sizer = VT.Resize((image_size,image_size))\n",
    "        self.timeMasking = T.TimeMasking(time_mask_param=int(config.win_size*0.4), iid_masks=True)\n",
    "        self.freqMasking = T.FrequencyMasking(freq_mask_param=int((config.NFFT//4)*0.15), iid_masks=True)\n",
    "        self.norm_layer = Normalization(mode='framewise')\n",
    "        self.pcen_layer = PCENTransform(eps=1e-6, s=0.025, alpha=0.6, delta=0.1, r=0.2, trainable=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # first compute spectrogram\n",
    "        spec = self.spec_layer(x)  # (B, F, T)\n",
    "        # normalize\n",
    "#         spec = spec.transpose(1,2) # (B, T, F)\n",
    "        spec = self.pcen_layer(spec)\n",
    "        spec = self.norm_layer(spec)\n",
    "        \n",
    "#         if self.training:\n",
    "        spec = self.timeMasking(spec)\n",
    "        spec = self.freqMasking(spec)\n",
    "\n",
    "        # then size for CNN model\n",
    "        # and create a channel\n",
    "        spec = self.sizer(spec)\n",
    "        x = spec.unsqueeze(1)\n",
    "        # then repeat channels\n",
    "        x = self.backbone(x)\n",
    "        #print(\"x shape = \" + str(x.shape))\n",
    "        #print(\"x = \" +str(x))\n",
    "        #pred = nn.Softmax(x)\n",
    "        pred = x\n",
    "        #print(np.argmax(pred.detach().cpu().numpy()))\n",
    "        #print(pred)\n",
    "        output = {\"prediction\": pred,\n",
    "                  \"spectrogram\": spec}\n",
    "        #print(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5524abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = torch.rand(1,15360)\n",
    "\n",
    "# model =Model('convnext_small',224)\n",
    "# op = model(test)\n",
    "# print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4915599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "30210\n",
      "i = 1\n",
      "14191\n",
      "i = 2\n",
      "2322\n",
      "i = 3\n",
      "13202\n",
      "i = 4\n",
      "3546\n",
      "i = 5\n",
      "1967\n",
      "i = 6\n",
      "2819\n",
      "i = 7\n",
      "1257\n",
      "i = 8\n",
      "27645\n",
      "class_sample_count = [30210, 14191, 2322, 13202, 3546, 1967, 2819, 1257, 27645]\n",
      "weight = [3.31016220e-05 7.04671975e-05 4.30663221e-04 7.57460991e-05\n",
      " 2.82007896e-04 5.08388409e-04 3.54735722e-04 7.95544948e-04\n",
      " 3.61729065e-05]\n",
      "samples_weight = [3.31016220e-05 7.04671975e-05 4.30663221e-04 7.57460991e-05\n",
      " 2.82007896e-04 5.08388409e-04 3.54735722e-04 7.95544948e-04\n",
      " 3.61729065e-05]\n"
     ]
    }
   ],
   "source": [
    "#https://discuss.pytorch.org/t/how-to-handle-imbalanced-classes/11264\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "class_sample_count = []\n",
    "for i in range(0,len(classes)):\n",
    "    df_temp = df_train_offset[df_train_offset['specie_ind'] == i]\n",
    "    print(\"i = \" +str(i))\n",
    "    print(len(df_temp))\n",
    "    class_sample_count.append(len(df_temp))\n",
    "print(\"class_sample_count = \" + str(class_sample_count))\n",
    "class_sample_count_arr = np.array(class_sample_count)\n",
    "weight = 1. / class_sample_count_arr\n",
    "print(\"weight = \" +str(weight))\n",
    "samples_weight = []\n",
    "for t in range(len(classes)):\n",
    "    samples_weight.append(weight[t])\n",
    "    \n",
    "samples_weight = np.array(samples_weight)\n",
    "print(\"samples_weight = \" +str(samples_weight))\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "sampler = WeightedRandomSampler(samples_weight, len(classes))\n",
    "  \n",
    "# class_sample_count = np.array( [len(np.where(target == t)[0]) for t in np.unique(target)])\n",
    "# weight = 1. / class_sample_count\n",
    "# samples_weight = np.array([weight[t] for t in target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50f1652f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>specie_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52168</td>\n",
       "      <td>220489</td>\n",
       "      <td>66561</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113652</td>\n",
       "      <td>222318</td>\n",
       "      <td>66561</td>\n",
       "      <td>33.220000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70368</td>\n",
       "      <td>221598</td>\n",
       "      <td>7681</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21340</td>\n",
       "      <td>221209</td>\n",
       "      <td>20481</td>\n",
       "      <td>20.480000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44053</td>\n",
       "      <td>220156</td>\n",
       "      <td>10241</td>\n",
       "      <td>35.780000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97154</th>\n",
       "      <td>126986</td>\n",
       "      <td>222482</td>\n",
       "      <td>58881</td>\n",
       "      <td>46.020000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97155</th>\n",
       "      <td>54523</td>\n",
       "      <td>221086</td>\n",
       "      <td>2561</td>\n",
       "      <td>17.860000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97156</th>\n",
       "      <td>8797</td>\n",
       "      <td>821</td>\n",
       "      <td>30721</td>\n",
       "      <td>11.146355</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97157</th>\n",
       "      <td>104679</td>\n",
       "      <td>222221</td>\n",
       "      <td>225281</td>\n",
       "      <td>35.780000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97158</th>\n",
       "      <td>89465</td>\n",
       "      <td>221987</td>\n",
       "      <td>35841</td>\n",
       "      <td>23.040000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97159 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index      id  offset     length  specie_ind\n",
       "0       52168  220489   66561  28.100000           4\n",
       "1      113652  222318   66561  33.220000           1\n",
       "2       70368  221598    7681  15.300000           3\n",
       "3       21340  221209   20481  20.480000           0\n",
       "4       44053  220156   10241  35.780000           0\n",
       "...       ...     ...     ...        ...         ...\n",
       "97154  126986  222482   58881  46.020000           0\n",
       "97155   54523  221086    2561  17.860000           0\n",
       "97156    8797     821   30721  11.146355           8\n",
       "97157  104679  222221  225281  35.780000           0\n",
       "97158   89465  221987   35841  23.040000           3\n",
       "\n",
       "[97159 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b526a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee31b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MozDataset(df_train_offset,  config.data_dir, min_length)\n",
    "val_dataset = MozDataset(df_val_offset,  config.data_dir, min_length)\n",
    "test_dataset = MozDataset(df_test_offset,  config.data_dir, min_length)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, num_workers=num_workers,sampler = sampler,batch_size = batch_size\n",
    "    , pin_memory=True )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size,\n",
    "        num_workers= num_workers, pin_memory=pin_memory,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607be0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "231957b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset = 97159\n",
      "Length of train loader = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train dataset = \" +str(len(train_dataset)))\n",
    "print(\"Length of train loader = \" +str(len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f589552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iter = iter(val_loader)\n",
    "# a,b = test_iter.next()\n",
    "# print(a.shape)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c69ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test block\n",
    "\n",
    "#temp_ten = torch.rand(64, 9, 1, 15360)\n",
    "# temp_ten.shape\n",
    "# bat_len = temp_ten.shape[0]\n",
    "# print(\"bat_len = \" +str(bat_len))\n",
    "# for i in range (bat_len):\n",
    "#     print(\"i = \" + str(i))\n",
    "#     elem = temp_ten[i,:,:,:]\n",
    "#     print(\"elem shape = \" +str(elem.shape))\n",
    "#     for j in range(elem.shape[0]):\n",
    "#         img = elem[j,:,:]\n",
    "#         print(\"img shape = \" +str(img.shape))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b3426",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4adde72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97159"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bce667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling rate = 8000. Please make sure the sampling rate is correct in order toget a valid freq range\n",
      "STFT kernels created, time used = 0.0804 seconds\n",
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb092d2a1b1a4e8098bcea6c8303f5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0batch = 0 of 1duraation = 0.010221477349599202\n",
      "Saving model to: ../outputs/models/pytorch/model_e0_2022_09_13_23_07_10.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.30      0.00      0.00      9416\n",
      "culex pipiens complex       0.16      0.09      0.11      4384\n",
      "           ae aegypti       0.02      0.19      0.04       691\n",
      "       an funestus ss       0.22      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.17      0.06      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.02      0.02      0.02       874\n",
      "         ma africanus       0.02      0.65      0.03       401\n",
      "               others       0.33      0.02      0.03      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.12      0.13      0.04     30363\n",
      "         weighted avg       0.24      0.04      0.03     30363\n",
      "\n",
      "Epoch: 0, Train Loss: 2.24978304, Train Acc: 0.00000000, Val Loss: 0.00949174, Val Acc: 0.03705228, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e582ab263214e618b032886a93e684a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1batch = 0 of 1duraation = 0.008491055170694987\n",
      "Saving model to: ../outputs/models/pytorch/model_e1_2022_09_13_23_16_59.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.30      0.00      0.00      9416\n",
      "culex pipiens complex       0.15      0.10      0.12      4384\n",
      "           ae aegypti       0.03      0.22      0.05       691\n",
      "       an funestus ss       0.15      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.15      0.06      1181\n",
      "          an coustani       0.02      0.01      0.01       592\n",
      "         ma uniformis       0.03      0.03      0.03       874\n",
      "         ma africanus       0.01      0.58      0.03       401\n",
      "               others       0.41      0.02      0.04      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.25      0.04      0.03     30363\n",
      "\n",
      "Epoch: 1, Train Loss: 2.22200513, Train Acc: 0.00000000, Val Loss: 0.00948381, Val Acc: 0.03709345, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e61f6fffb34396aae800567e45b1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 2batch = 0 of 1duraation = 0.00889214277267456\n",
      "Saving model to: ../outputs/models/pytorch/model_e2_2022_09_13_23_26_45.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.37      0.00      0.00      9416\n",
      "culex pipiens complex       0.15      0.08      0.11      4384\n",
      "           ae aegypti       0.02      0.16      0.04       691\n",
      "       an funestus ss       0.14      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.15      0.06      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.03      0.03       874\n",
      "         ma africanus       0.02      0.64      0.03       401\n",
      "               others       0.38      0.02      0.04      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.26      0.04      0.03     30363\n",
      "\n",
      "Epoch: 2, Train Loss: 2.23958325, Train Acc: 0.00000000, Val Loss: 0.00949286, Val Acc: 0.03734047, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f535a2842c40a6bc65c4eccf5df351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 3batch = 0 of 1duraation = 0.009604704380035401\n",
      "Saving model to: ../outputs/models/pytorch/model_e3_2022_09_13_23_36_29.pth\n",
      "Now printing classification rport... \n",
      "Saving model to: ../outputs/models/pytorch/model_e4_2022_09_13_23_46_14.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.24      0.00      0.00      9416\n",
      "culex pipiens complex       0.14      0.08      0.10      4384\n",
      "           ae aegypti       0.03      0.18      0.05       691\n",
      "       an funestus ss       0.23      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.16      0.06      1181\n",
      "          an coustani       0.01      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.03      0.03       874\n",
      "         ma africanus       0.01      0.61      0.03       401\n",
      "               others       0.34      0.02      0.04      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.12      0.12      0.04     30363\n",
      "         weighted avg       0.22      0.04      0.03     30363\n",
      "\n",
      "Epoch: 4, Train Loss: 2.23654509, Train Acc: 0.00000000, Val Loss: 0.00947214, Val Acc: 0.03861671, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3506757efb4a698a53f1b0655b81a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 5batch = 0 of 1duraation = 0.008830106258392334\n",
      "Saving model to: ../outputs/models/pytorch/model_e5_2022_09_13_23_55_56.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.32      0.00      0.00      9416\n",
      "culex pipiens complex       0.14      0.11      0.13      4384\n",
      "           ae aegypti       0.03      0.22      0.05       691\n",
      "       an funestus ss       0.23      0.01      0.02      4239\n",
      "         an squamosus       0.03      0.15      0.05      1181\n",
      "          an coustani       0.01      0.00      0.00       592\n",
      "         ma uniformis       0.02      0.03      0.02       874\n",
      "         ma africanus       0.02      0.56      0.03       401\n",
      "               others       0.39      0.02      0.04      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.26      0.04      0.04     30363\n",
      "\n",
      "Epoch: 5, Train Loss: 2.28363705, Train Acc: 0.00000000, Val Loss: 0.00945289, Val Acc: 0.03927542, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6a77fc1b25486297e1ef6c13398bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 6batch = 0 of 1duraation = 0.009122371673583984\n",
      "Saving model to: ../outputs/models/pytorch/model_e6_2022_09_14_00_05_39.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.36      0.00      0.01      9416\n",
      "culex pipiens complex       0.13      0.08      0.10      4384\n",
      "           ae aegypti       0.03      0.19      0.04       691\n",
      "       an funestus ss       0.14      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.17      0.06      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.03      0.03       874\n",
      "         ma africanus       0.02      0.60      0.03       401\n",
      "               others       0.40      0.02      0.05      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.27      0.04      0.03     30363\n",
      "\n",
      "Epoch: 6, Train Loss: 2.26692700, Train Acc: 0.00000000, Val Loss: 0.00945840, Val Acc: 0.03960478, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92798ad18a3d46bab477efa69e496190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 7batch = 0 of 1duraation = 0.009362836678822836\n",
      "Saving model to: ../outputs/models/pytorch/model_e7_2022_09_14_00_15_24.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.28      0.00      0.01      9416\n",
      "culex pipiens complex       0.16      0.09      0.12      4384\n",
      "           ae aegypti       0.03      0.21      0.05       691\n",
      "       an funestus ss       0.16      0.00      0.00      4239\n",
      "         an squamosus       0.04      0.14      0.06      1181\n",
      "          an coustani       0.03      0.01      0.01       592\n",
      "         ma uniformis       0.02      0.03      0.03       874\n",
      "         ma africanus       0.01      0.59      0.03       401\n",
      "               others       0.40      0.02      0.04      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.12      0.12      0.04     30363\n",
      "         weighted avg       0.25      0.04      0.04     30363\n",
      "\n",
      "Epoch: 7, Train Loss: 2.22656250, Train Acc: 0.00000000, Val Loss: 0.00945850, Val Acc: 0.04228077, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ef209bbc2340b7abcbf3d5fca6444e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 8batch = 0 of 1duraation = 0.008561031023661295\n",
      "Epoch: 8, Train Loss: 2.20008683, Train Acc: 0.33333333, Val Loss: 0.00946643, Val Acc: 0.03878139, overrun_counter 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeb25ad19d2409bbd7da5c31641b384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 9batch = 0 of 1duraation = 0.008786348501841228\n",
      "Saving model to: ../outputs/models/pytorch/model_e9_2022_09_14_00_29_28.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.36      0.00      0.01      9416\n",
      "culex pipiens complex       0.14      0.09      0.11      4384\n",
      "           ae aegypti       0.03      0.20      0.05       691\n",
      "       an funestus ss       0.18      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.12      0.06      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.04      0.04       874\n",
      "         ma africanus       0.01      0.59      0.03       401\n",
      "               others       0.39      0.02      0.05      8585\n",
      "\n",
      "             accuracy                           0.04     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.27      0.04      0.04     30363\n",
      "\n",
      "Epoch: 9, Train Loss: 2.21310759, Train Acc: 0.00000000, Val Loss: 0.00944450, Val Acc: 0.04343351, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167072f0dc8643bfaff04245081d8b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 10batch = 0 of 1duraation = 0.008678130308787028\n",
      "Epoch: 10, Train Loss: 2.16276050, Train Acc: 0.22222222, Val Loss: 0.00944180, Val Acc: 0.04096336, overrun_counter 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60328640f1c24a47a5efeb394c74d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 11batch = 0 of 1duraation = 0.009405442078908284\n",
      "Epoch: 11, Train Loss: 2.27061629, Train Acc: 0.00000000, Val Loss: 0.00942996, Val Acc: 0.04207493, overrun_counter 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd9fa4d328e4b5f8da7c10126578704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 12batch = 0 of 1duraation = 0.008890334765116375\n",
      "Epoch: 12, Train Loss: 2.26019955, Train Acc: 0.00000000, Val Loss: 0.00942100, Val Acc: 0.04269247, overrun_counter 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652f97646d1846b4826de0bdb19eb092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 13batch = 0 of 1duraation = 0.008684198061625162\n",
      "Epoch: 13, Train Loss: 2.31727433, Train Acc: 0.00000000, Val Loss: 0.00940270, Val Acc: 0.04277480, overrun_counter 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f862657eab425fae9b1209f8e81e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 14batch = 0 of 1duraation = 0.009181153774261475\n",
      "Saving model to: ../outputs/models/pytorch/model_e14_2022_09_14_00_56_25.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.37      0.02      0.03      9416\n",
      "culex pipiens complex       0.15      0.10      0.12      4384\n",
      "           ae aegypti       0.02      0.16      0.04       691\n",
      "       an funestus ss       0.18      0.00      0.01      4239\n",
      "         an squamosus       0.03      0.11      0.05      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.09      0.04       874\n",
      "         ma africanus       0.02      0.58      0.03       401\n",
      "               others       0.37      0.03      0.06      8585\n",
      "\n",
      "             accuracy                           0.05     30363\n",
      "            macro avg       0.13      0.12      0.04     30363\n",
      "         weighted avg       0.27      0.05      0.05     30363\n",
      "\n",
      "Epoch: 14, Train Loss: 2.19748259, Train Acc: 0.22222222, Val Loss: 0.00938954, Val Acc: 0.04936188, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82448b4a1ed34741ac00f8e7ec322022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 15batch = 0 of 1duraation = 0.009028311570485432\n",
      "Epoch: 15, Train Loss: 2.20952702, Train Acc: 0.33333333, Val Loss: 0.00938567, Val Acc: 0.04755043, overrun_counter 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574db769f27c467dbcc62d0a2c1d4b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 16batch = 0 of 1duraation = 0.008904731273651123\n",
      "Saving model to: ../outputs/models/pytorch/model_e16_2022_09_14_01_10_28.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.31      0.01      0.03      9416\n",
      "culex pipiens complex       0.15      0.10      0.12      4384\n",
      "           ae aegypti       0.03      0.20      0.05       691\n",
      "       an funestus ss       0.15      0.01      0.01      4239\n",
      "         an squamosus       0.03      0.08      0.05      1181\n",
      "          an coustani       0.01      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.11      0.05       874\n",
      "         ma africanus       0.01      0.55      0.03       401\n",
      "               others       0.36      0.04      0.07      8585\n",
      "\n",
      "             accuracy                           0.05     30363\n",
      "            macro avg       0.12      0.12      0.04     30363\n",
      "         weighted avg       0.24      0.05      0.05     30363\n",
      "\n",
      "Epoch: 16, Train Loss: 2.20247388, Train Acc: 0.00000000, Val Loss: 0.00937449, Val Acc: 0.05055578, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d5e3767b5448d19860afb02b874ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 17batch = 0 of 1duraation = 0.009655161698659261\n",
      "Saving model to: ../outputs/models/pytorch/model_e17_2022_09_14_01_20_10.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.30      0.02      0.03      9416\n",
      "culex pipiens complex       0.15      0.11      0.13      4384\n",
      "           ae aegypti       0.03      0.15      0.04       691\n",
      "       an funestus ss       0.09      0.00      0.01      4239\n",
      "         an squamosus       0.04      0.09      0.05      1181\n",
      "          an coustani       0.03      0.00      0.01       592\n",
      "         ma uniformis       0.02      0.13      0.04       874\n",
      "         ma africanus       0.02      0.53      0.03       401\n",
      "               others       0.32      0.03      0.06      8585\n",
      "\n",
      "             accuracy                           0.05     30363\n",
      "            macro avg       0.11      0.12      0.04     30363\n",
      "         weighted avg       0.22      0.05      0.05     30363\n",
      "\n",
      "Epoch: 17, Train Loss: 2.26280379, Train Acc: 0.22222222, Val Loss: 0.00934333, Val Acc: 0.05701935, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0504565776e842799497374bd3b9ee3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 18batch = 0 of 1duraation = 0.008548327287038167\n",
      "Epoch: 18, Train Loss: 2.25661898, Train Acc: 0.33333333, Val Loss: 0.00933339, Val Acc: 0.05685467, overrun_counter 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22912f18a5e46b4b0cf9cd1ec0b7fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 19batch = 0 of 1duraation = 0.009610148270924886\n",
      "Saving model to: ../outputs/models/pytorch/model_e19_2022_09_14_01_34_11.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.30      0.05      0.08      9416\n",
      "culex pipiens complex       0.15      0.12      0.13      4384\n",
      "           ae aegypti       0.02      0.13      0.04       691\n",
      "       an funestus ss       0.15      0.01      0.01      4239\n",
      "         an squamosus       0.04      0.09      0.05      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.18      0.05       874\n",
      "         ma africanus       0.01      0.48      0.03       401\n",
      "               others       0.34      0.04      0.07      8585\n",
      "\n",
      "             accuracy                           0.06     30363\n",
      "            macro avg       0.12      0.12      0.05     30363\n",
      "         weighted avg       0.23      0.06      0.07     30363\n",
      "\n",
      "Epoch: 19, Train Loss: 2.17447925, Train Acc: 0.11111111, Val Loss: 0.00930798, Val Acc: 0.06323590, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d405e91858684b0d84f0b1abaeb2da7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 20batch = 0 of 1duraation = 0.009092990557352703\n",
      "Saving model to: ../outputs/models/pytorch/model_e20_2022_09_14_01_43_54.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.32      0.07      0.12      9416\n",
      "culex pipiens complex       0.15      0.12      0.13      4384\n",
      "           ae aegypti       0.02      0.10      0.04       691\n",
      "       an funestus ss       0.20      0.01      0.03      4239\n",
      "         an squamosus       0.04      0.08      0.05      1181\n",
      "          an coustani       0.02      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.20      0.05       874\n",
      "         ma africanus       0.02      0.44      0.03       401\n",
      "               others       0.32      0.04      0.08      8585\n",
      "\n",
      "             accuracy                           0.07     30363\n",
      "            macro avg       0.12      0.12      0.06     30363\n",
      "         weighted avg       0.24      0.07      0.09     30363\n",
      "\n",
      "Epoch: 20, Train Loss: 2.17339420, Train Acc: 0.11111111, Val Loss: 0.00929085, Val Acc: 0.07393989, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d4dec4ad2e4c50acf6a80b18460b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 21batch = 0 of 1duraation = 0.008669817447662353\n",
      "Saving model to: ../outputs/models/pytorch/model_e21_2022_09_14_01_53_38.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.32      0.10      0.15      9416\n",
      "culex pipiens complex       0.14      0.12      0.13      4384\n",
      "           ae aegypti       0.02      0.11      0.04       691\n",
      "       an funestus ss       0.14      0.02      0.03      4239\n",
      "         an squamosus       0.04      0.07      0.05      1181\n",
      "          an coustani       0.05      0.00      0.01       592\n",
      "         ma uniformis       0.03      0.23      0.05       874\n",
      "         ma africanus       0.01      0.32      0.03       401\n",
      "               others       0.31      0.05      0.08      8585\n",
      "\n",
      "             accuracy                           0.08     30363\n",
      "            macro avg       0.12      0.11      0.06     30363\n",
      "         weighted avg       0.23      0.08      0.10     30363\n",
      "\n",
      "Epoch: 21, Train Loss: 2.22374129, Train Acc: 0.22222222, Val Loss: 0.00927373, Val Acc: 0.08283244, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686c045e5d7148e086d5e21cb4bdfa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 22batch = 0 of 1duraation = 0.008623023827870687\n",
      "Saving model to: ../outputs/models/pytorch/model_e22_2022_09_14_02_03_22.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.30      0.12      0.17      9416\n",
      "culex pipiens complex       0.15      0.12      0.13      4384\n",
      "           ae aegypti       0.02      0.08      0.03       691\n",
      "       an funestus ss       0.17      0.03      0.05      4239\n",
      "         an squamosus       0.04      0.07      0.05      1181\n",
      "          an coustani       0.10      0.01      0.01       592\n",
      "         ma uniformis       0.03      0.25      0.05       874\n",
      "         ma africanus       0.02      0.35      0.03       401\n",
      "               others       0.32      0.05      0.08      8585\n",
      "\n",
      "             accuracy                           0.09     30363\n",
      "            macro avg       0.13      0.12      0.07     30363\n",
      "         weighted avg       0.23      0.09      0.11     30363\n",
      "\n",
      "Epoch: 22, Train Loss: 2.13140202, Train Acc: 0.33333333, Val Loss: 0.00925536, Val Acc: 0.09205434, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a41d6be75bf428b9f018a40cd4ee2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 23batch = 0 of 1duraation = 0.008489735921223958\n",
      "Saving model to: ../outputs/models/pytorch/model_e23_2022_09_14_02_13_05.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.31      0.15      0.20      9416\n",
      "culex pipiens complex       0.15      0.11      0.13      4384\n",
      "           ae aegypti       0.02      0.09      0.04       691\n",
      "       an funestus ss       0.15      0.02      0.04      4239\n",
      "         an squamosus       0.04      0.08      0.06      1181\n",
      "          an coustani       0.04      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.31      0.06       874\n",
      "         ma africanus       0.02      0.32      0.03       401\n",
      "               others       0.33      0.05      0.08      8585\n",
      "\n",
      "             accuracy                           0.10     30363\n",
      "            macro avg       0.12      0.13      0.07     30363\n",
      "         weighted avg       0.24      0.10      0.12     30363\n",
      "\n",
      "Epoch: 23, Train Loss: 2.07910156, Train Acc: 0.66666667, Val Loss: 0.00923662, Val Acc: 0.10263483, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62d8b64e39545c486f9c719b7636c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 24batch = 0 of 1duraation = 0.008877789974212647\n",
      "Saving model to: ../outputs/models/pytorch/model_e24_2022_09_14_02_22_47.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.32      0.20      0.25      9416\n",
      "culex pipiens complex       0.15      0.12      0.14      4384\n",
      "           ae aegypti       0.02      0.05      0.03       691\n",
      "       an funestus ss       0.17      0.04      0.07      4239\n",
      "         an squamosus       0.05      0.07      0.06      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.33      0.06       874\n",
      "         ma africanus       0.02      0.22      0.03       401\n",
      "               others       0.32      0.05      0.09      8585\n",
      "\n",
      "             accuracy                           0.12     30363\n",
      "            macro avg       0.12      0.12      0.08     30363\n",
      "         weighted avg       0.24      0.12      0.14     30363\n",
      "\n",
      "Epoch: 24, Train Loss: 2.13671875, Train Acc: 0.00000000, Val Loss: 0.00922357, Val Acc: 0.11226842, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77da604e24cf48fa85c7d077791a328f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 25batch = 0 of 1duraation = 0.008826029300689698\n",
      "Saving model to: ../outputs/models/pytorch/model_e25_2022_09_14_02_32_29.pth\n",
      "Now printing classification rport... \n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "        an arabiensis       0.32      0.25      0.29      9416\n",
      "culex pipiens complex       0.17      0.10      0.13      4384\n",
      "           ae aegypti       0.03      0.04      0.03       691\n",
      "       an funestus ss       0.16      0.05      0.08      4239\n",
      "         an squamosus       0.03      0.05      0.04      1181\n",
      "          an coustani       0.00      0.00      0.00       592\n",
      "         ma uniformis       0.03      0.33      0.05       874\n",
      "         ma africanus       0.02      0.22      0.03       401\n",
      "               others       0.32      0.06      0.10      8585\n",
      "\n",
      "             accuracy                           0.13     30363\n",
      "            macro avg       0.12      0.12      0.08     30363\n",
      "         weighted avg       0.24      0.13      0.15     30363\n",
      "\n",
      "Epoch: 25, Train Loss: 2.15321183, Train Acc: 0.11111111, Val Loss: 0.00920488, Val Acc: 0.12177851, overrun_counter 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79815028a3314eb794529e9d7943d09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 26batch = 0 of 1duraation = 0.009237901369730631\n",
      "Saving model to: ../outputs/models/pytorch/model_e26_2022_09_14_02_42_11.pth\n",
      "Now printing classification rport... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1381563/2374612059.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'convnext_small'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#train_loader, val_loader, model = None,  classes = classes,n_channels = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1381563/1767021221.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, test_loader, model, classes, num_epochs, n_channels)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now printing classification rport... \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mall_y_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_y_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_y_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_y_pred_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1381563/4015467461.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, loader, criterion, classes, device, call)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of loader = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loader index = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model =Model('convnext_small',224)\n",
    "#train_loader, val_loader, model = None,  classes = classes,n_channels = 1\n",
    "model, lr_log = train_model(train_loader, val_loader, test_loader,model, classes , num_epochs = num_epochs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e1dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction  = [2.0, 3.0, 8.0, 2.0, 8.0, 8.0, 4.0, 0.0, 7.0, 8.0, 8.0, 2.0, 8.0, 0.0, 1.0, 3.0, 4.0, 8.0, 5.0, 8.0, 2.0, 2.0, 2.0, 0.0, 5.0, 5.0, 3.0, 8.0, 4.0, 1.0, 2.0, 5.0, 6.0, 1.0, 8.0, 0.0, 2.0, 4.0, 6.0, 8.0, 7.0, 0.0, 7.0, 0.0, 8.0, 5.0, 8.0, 2.0, 0.0, 0.0, 4.0, 7.0, 5.0, 4.0, 1.0, 2.0, 4.0, 1.0, 6.0, 4.0, 3.0, 7.0, 8.0, 8.0, 0.0, 6.0, 7.0, 1.0, 6.0, 5.0, 7.0, 0.0, 5.0, 0.0, 0.0, 2.0, 1.0, 5.0, 8.0, 1.0, 5.0, 7.0, 5.0, 7.0, 3.0, 6.0, 6.0, 6.0, 2.0, 6.0, 2.0, 6.0, 6.0, 3.0, 6.0, 6.0, 0.0, 4.0, 6.0, 6.0, 0.0, 8.0, 7.0, 1.0, 4.0, 1.0, 3.0, 0.0, 8.0, 6.0, 5.0, 7.0, 7.0, 3.0, 2.0, 0.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 7.0, 3.0, 1.0, 3.0, 6.0, 5.0, 5.0, 2.0, 0.0, 2.0, 0.0, 6.0, 3.0, 0.0, 3.0, 4.0, 8.0, 6.0, 4.0, 6.0, 0.0, 4.0, 5.0, 2.0, 6.0, 1.0, 1.0, 5.0, 4.0, 6.0, 5.0, 8.0, 0.0, 3.0, 4.0, 4.0, 4.0, 8.0, 8.0, 5.0, 5.0, 0.0, 1.0, 3.0, 3.0, 7.0, 7.0, 1.0, 5.0, 7.0, 6.0, 5.0, 8.0, 3.0, 8.0, 5.0, 2.0, 3.0, 7.0, 3.0, 7.0, 8.0, 4.0, 2.0, 0.0, 6.0, 8.0, 1.0, 3.0, 6.0, 2.0, 2.0, 7.0, 7.0, 2.0, 0.0, 4.0, 8.0]\n",
    "Label   = [3.0, 5.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 4.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 8.0, 8.0, 8.0, 3.0, 4.0, 7.0, 6.0, 4.0, 1.0, 3.0, 0.0, 7.0, 7.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 4.0, 2.0, 8.0, 8.0, 7.0, 4.0, 7.0, 2.0, 6.0, 1.0, 8.0, 4.0, 8.0, 0.0, 1.0, 4.0, 2.0, 2.0, 0.0, 8.0, 1.0, 7.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 5.0, 4.0, 0.0, 5.0, 8.0, 5.0, 7.0, 1.0, 1.0, 6.0, 8.0, 6.0, 6.0, 4.0, 6.0, 6.0, 6.0, 8.0, 4.0, 5.0, 8.0, 0.0, 7.0, 4.0, 1.0, 6.0, 1.0, 5.0, 5.0, 5.0, 3.0, 8.0, 7.0, 8.0, 1.0, 2.0, 7.0, 2.0, 0.0, 4.0, 3.0, 2.0, 5.0, 1.0, 1.0, 2.0, 3.0, 0.0, 4.0, 7.0, 5.0, 2.0, 2.0, 6.0, 7.0, 2.0, 2.0, 6.0, 4.0, 2.0, 5.0, 8.0, 3.0, 6.0, 1.0, 1.0, 6.0, 5.0, 0.0, 2.0, 5.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 0.0, 6.0, 3.0, 7.0, 1.0, 2.0, 7.0, 3.0, 6.0, 1.0, 3.0, 8.0, 3.0, 6.0, 1.0, 4.0, 4.0, 6.0, 2.0, 5.0, 3.0, 0.0, 5.0, 7.0, 3.0, 5.0, 6.0, 4.0, 7.0, 1.0, 1.0, 6.0, 1.0, 4.0, 5.0, 8.0, 4.0, 6.0, 4.0, 5.0, 1.0, 6.0, 0.0, 3.0, 3.0, 3.0, 4.0, 7.0, 5.0, 2.0, 6.0, 2.0, 4.0]\n",
    "print(classification_report(np.array(Label), np.array(prediction), target_names= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0428b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "pred = []\n",
    "for i in range(10):\n",
    "    label.append(np.random.rand(9))\n",
    "    pred.append(np.random.rand(9))\n",
    "print(label)\n",
    "print(pred)\n",
    "print(classification_report(label, pred, target_names= classes, labels= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(8, device = \"cuda\")\n",
    "print(label)\n",
    "label_cpu = label.cpu().detach()\n",
    "print(label_cpu)\n",
    "label_np = label_cpu.numpy()\n",
    "print(type(label_np))\n",
    "label_np_item = label_np.item()\n",
    "print(type(label_np_item))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.randn(4,9)\n",
    "y_pred.shape\n",
    "#y_pred_np = y_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_np\n",
    "# y_pred_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    print(\"idx = \" + str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a5b2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
